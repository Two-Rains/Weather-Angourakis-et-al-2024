[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Supplementary materials to Angourakis et al. (2025)",
    "section": "",
    "text": "1 Introduction\nThis file and all other referenced in the code can be found at the repository: https://github.com/Two-Rains/Weather-Angourakis-et-al-2025",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#about-this-document",
    "href": "index.html#about-this-document",
    "title": "Supplementary materials to Angourakis et al. (2025)",
    "section": "1.1 About this document",
    "text": "1.1 About this document\nTo facilitate a deeper understanding and application of the Weather model, this resource contains all the source code for the figures presented in the related paper (Angourakis, Baudouin, and Petrie, in submission), including:\n\nVisualizing weather variables in example locations.\nDemonstrating the full model functionality.\nVisualizing parameter sensitivity for solar radiation and temperature generation.\nVisualizing parameter sensitivity for precipitation generation.\nA walk-through on the calibration of parameters.\nA calibration workflow for example locations.\n\nThese materials offer hands-on guidance for users looking to implement, calibrate, and analyse the Weather model in their own research.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#about-the-weather-model",
    "href": "index.html#about-the-weather-model",
    "title": "Supplementary materials to Angourakis et al. (2025)",
    "section": "1.2 About the Weather model",
    "text": "1.2 About the Weather model\nThe Weather model is a procedural generation model designed to produce random synthetic daily weather time series with realistic characteristics, given a set of parameters. It is implemented in NetLogo and R and is computationally efficient. The Weather model generates synthetic weather time series using algorithms based on sinusoidal and double logistic functions, incorporating stochastic variation to mimic unpredictable weather patterns. It produces daily values of surface solar radiation, average/max/min temperature, and total precipitation.\nMore details about the two implementation at:\n\nODD document for the NetLogo implementation\nODD document for the R implementation\n\n\n1.2.1 Parameters and hyperparameters\n\n\n\n\n\n\nparameter\ndescription\n\n\n\n\nyear_length\nNumber of days per year\n\n\nsouthern_hemisphere\nWhether the annual curve corresponds to values in the southern or northern hemisphere\n\n\ntemperature - annual_max\nAnnual maximum of daily mean temperature\n\n\ntemperature - annual_min\nAnnual minimum of daily mean temperature\n\n\ntemperature - daily_fluctuation\nStandard deviation in daily mean temperature\n\n\ntemperature - daily_lower_dev\nLower deviation from daily mean temperature\n\n\ntemperature - daily_upper_dev\nUpper deviation from daily mean temperature\n\n\nsolar - annual_max\nAnnual maximum of daily mean solar radiation\n\n\nsolar - annual_min\nAnnual minimum of daily mean solar radiation\n\n\nsolar - daily_fluctuation\nStandard deviation in daily mean solar radiation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhyperparameter\nparameter (year)\ndescription\n\n\n\n\n\nyear_length\nNumber of days per year\n\n\nannual_sum\nprecipitation - annual_sum_mean\nMean and\n\n\nannual_sum\nprecipitation - annual_sum_sd\nstandard deviation in annual sum of precipitation\n\n\nn_samples\nprecipitation - plateau_value_mean\nMean and\n\n\nn_samples\nprecipitation - plateau_value_sd\nstandard deviation in number of random samples (steps) during descritisation of cumulative precipitation curves (an approximation to the number of precipitation events)\n\n\nmax_sample_size\nprecipitation - inflection1_mean\nMean and\n\n\nmax_sample_size\nprecipitation - inflection1_sd\nstandard deviation in maximum length of samples (steps) during descritisation of cumulative precipitation curves (an approximation to the duration between precipitation events)\n\n\nplateau_value\nprecipitation - rate1_mean\nMean and\n\n\nplateau_value\nprecipitation - rate1_sd\nstandard deviation in value in which the gap between logistic curves is set (range of 0 to 1); interpretable as the proportion of precipitation falling in the first rainy season\n\n\ninflection1\nprecipitation - inflection2_mean\nMean and\n\n\ninflection1\nprecipitation - inflection2_sd\nstandard deviation in day of year in which the first logistic curves has its maximum slope; interpretable as the peak day of the first rainy season\n\n\nrate1\nprecipitation - rate2_mean\nMean and\n\n\nrate1\nprecipitation - rate2_sd\nstandard deviation in maximum rate or slope increase of the first logistic curves; interpretable as the maximum daily precipitation of the first rainy season\n\n\ninflection2\nprecipitation - n_samples_mean\nMean and\n\n\ninflection2\nprecipitation - n_samples_sd\nstandard deviation in day of year in which the second logistic curves has its maximum slope; interpretable as the peak day of the second rainy season\n\n\nrate2\nprecipitation - max_sample_size_mean\nMean and\n\n\nrate2\nprecipitation - max_sample_size_sd\nstandard deviation in maximum rate or slope increase of the second logistic curves; interpretable as the maximum daily precipitation of the second rainy season",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#context-of-the-weather-model-within-the-indus-village-model",
    "href": "index.html#context-of-the-weather-model-within-the-indus-village-model",
    "title": "Supplementary materials to Angourakis et al. (2025)",
    "section": "1.3 Context of the Weather model within the Indus Village model",
    "text": "1.3 Context of the Weather model within the Indus Village model\n\n\n\nRoute of model integration in the Indus Village\n\n\n\n\n\nThe weather variables and the key interface variables of the related models\n\n\n\n\n\nThe connections between weather variables and the key interface variables of the related models",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "weather-examples.html",
    "href": "weather-examples.html",
    "title": "2  Daily weather in example locations",
    "section": "",
    "text": "Choose file format for generated figures:\n\noutput_dir &lt;- \"output\"\nplot_file_format &lt;- c(\"png\", \"eps\")[1] # modify index number to change format\n\nLoad source file containing the R implementation of the Weather model:\n\nsource(\"source/weatherModel.R\")\n\nWe use the data downloaded at NASA´s POWER access viewer (power.larc.nasa.gov/data-access-viewer/) selecting the user community ‘Agroclimatology’ and pin pointing the different locations between 01/01/1984 and 31/12/2007. The exact locations are:\n\nRakhigarhi, Haryana, India (Latitude: 29.1687, Longitude: 76.0687)\n\nIrkutsk, Irkutsk Óblast, Russia (Latitude: 52.2891, Longitude: 104.2493)\nHobart, Tasmania, Australia (Latitude: -42.8649, Longitude: 147.3441)\nPearl Harbor, Hawaii, United States of America (Latitude: 21.376, Longitude: -157.9708)\nSão Paulo, Brazil (Latitude: -23.5513, Longitude: -46.6344)\nCambridge, United Kingdom (Latitude: 52.2027, Longitude: 0.122)\nWindhoek, Namibia (Latitude: -22.5718, Longitude: 17.0953)\n\nWe selected the ICASA Format’s parameters:\n\nPrecipitation (PRECTOT)\n\nWind speed at 2m (WS2M)\n\nRelative Humidity at 2m (RH2M)\n\nDew/frost point at 2m (T2MDEW)\n\nMaximum temperature at 2m (T2M_MAX)\n\nMinimum temperature at 2m (T2M_MIN)\n\nAll sky insolation incident on a horizontal surface (ALLSKY_SFC_SW_DWN)\n\nTemperature at 2m (T2M)\n\nand from Solar Related Parameters:\n\nTop-of-atmosphere Insolation (ALLSKY_TOA_SW_DWN)\n\n\n# Function to read and filter weather data\nread_weather_data &lt;- function(file_path) {\n  data &lt;- read.csv(file_path, skip = 18)\n  data[data$YEAR %in% 1984:2007, ]\n}\n\n# Get input file paths\ninput_files &lt;- list.files(path = \"input\", full.names = TRUE)\n\n# Read and combine all weather data\nweather &lt;- do.call(rbind, lapply(input_files, read_weather_data))\n\n# Define site mapping\nsite_mapping &lt;- list(\n  list(condition = function(x) floor(x$LAT) == 29, site = \"Rakhigarhi\"),\n  list(condition = function(x) floor(x$LON) == 104, site = \"Irkutsk\"),\n  list(condition = function(x) floor(x$LAT) == -43, site = \"Hobart\"),\n  list(condition = function(x) floor(x$LAT) == 21, site = \"Pearl Harbor\"),\n  list(condition = function(x) floor(x$LAT) == -24, site = \"Sao Paulo\"),\n  list(condition = function(x) floor(x$LON) == 0, site = \"Cambridge\"),\n  list(condition = function(x) floor(x$LAT) == -23, site = \"Windhoek\")\n)\n\n# Assign sites based on latitude and longitude\nweather$Site &lt;- NA\nfor (mapping in site_mapping) {\n  weather$Site[mapping$condition(weather)] &lt;- mapping$site\n}\n\n# Calculate summary statistics\nyears &lt;- unique(weather$YEAR)\nnumber_of_years &lt;- length(years)\n\nPrepare display order according to latitude:\n\n# Create a function to format latitude\nformat_latitude &lt;- function(lat) {\n  paste(abs(round(lat, 2)), ifelse(lat &lt; 0, \"S\", \"N\"))\n}\n\n# Create and process sites_latitude data frame\nsites_latitude &lt;- data.frame(\n  Site = unique(weather$Site),\n  Latitude = as.numeric(unique(weather$LAT))\n)\n\n# Sort sites_latitude by descending latitude\nsites_latitude &lt;- sites_latitude[order(-sites_latitude$Latitude), ]\n\n# Format latitude values\nsites_latitude$Latitude &lt;- sapply(sites_latitude$Latitude, format_latitude)\n\n# calculate easy references to sites\nsites &lt;- sites_latitude$Site\nnumber_of_sites &lt;- length(sites)\n\nPrint summary:\n\ncat(\"Number of sites:\", number_of_sites, \"\\n\")\n\nNumber of sites: 7 \n\ncat(\"Sites:\", paste(sites, collapse = \", \"), \"\\n\")\n\nSites: Irkutsk, Cambridge, Rakhigarhi, Pearl Harbor, Windhoek, Sao Paulo, Hobart \n\ncat(\"Number of years:\", number_of_years, \"\\n\")\n\nNumber of years: 24 \n\ncat(\"Years:\", paste(range(years), collapse = \" - \"), \"\\n\")\n\nYears: 1984 - 2007 \n\n\nCompute statistics for each site and day of year:\n\n# Define summary statistics function\ncalculate_summary &lt;- function(data, column) {\n  c(mean = mean(data[[column]], na.rm = TRUE),\n    sd = sd(data[[column]], na.rm = TRUE),\n    max = max(data[[column]], na.rm = TRUE),\n    min = min(data[[column]], na.rm = TRUE),\n    error = qt(0.975, length(data[[column]]) - 1) * \n      sd(data[[column]], na.rm = TRUE) / \n      sqrt(length(data[[column]])))\n}\n\n# Initialize weather_summary as a data frame\nweather_summary &lt;- data.frame(\n  Site = character(),\n  dayOfYear = integer(),\n  solarRadiation.mean = numeric(),\n  solarRadiation.sd = numeric(),\n  solarRadiation.max = numeric(),\n  solarRadiation.min = numeric(),\n  solarRadiation.error = numeric(),\n  solarRadiationTop.mean = numeric(),\n  temperature.mean = numeric(),\n  temperature.sd = numeric(),\n  temperature.max = numeric(),\n  temperature.min = numeric(),\n  temperature.error = numeric(),\n  maxTemperature.mean = numeric(),\n  maxTemperature.max = numeric(),\n  maxTemperature.min = numeric(),\n  maxTemperature.error = numeric(),\n  minTemperature.mean = numeric(),\n  minTemperature.max = numeric(),\n  minTemperature.min = numeric(),\n  minTemperature.error = numeric(),\n  temperature.lowerDeviation = numeric(),\n  temperature.lowerDeviation.error = numeric(),\n  temperature.upperDeviation = numeric(),\n  temperature.upperDeviation.error = numeric(),\n  precipitation.mean = numeric(),\n  precipitation.max = numeric(),\n  precipitation.min = numeric(),\n  precipitation.error = numeric()\n)\n\n# Pre-allocate the weather_summary data frame\ntotal_rows &lt;- length(sites) * 366\nweather_summary &lt;- weather_summary[rep(1, total_rows), ]\n\n# Main loop\nrow_index &lt;- 1\nfor (site in sites) {\n  for (day in 1:366) {\n    temp_data &lt;- weather[weather$Site == site & weather$DOY == day, ]\n    \n    if (nrow(temp_data) == 0) next\n    \n    weather_summary[row_index, \"Site\"] &lt;- site\n    weather_summary[row_index, \"dayOfYear\"] &lt;- day\n    \n    # Solar radiation\n    solar_summary &lt;- calculate_summary(temp_data, \"ALLSKY_SFC_SW_DWN\")\n    weather_summary[row_index, c(\"solarRadiation.mean\", \"solarRadiation.sd\", \n                                \"solarRadiation.max\", \"solarRadiation.min\", \n                                \"solarRadiation.error\")] &lt;- solar_summary\n    \n    weather_summary[row_index, \"solarRadiationTop.mean\"] &lt;- mean(temp_data$ALLSKY_TOA_SW_DWN, na.rm = TRUE)\n    \n    # Temperature\n    temp_summary &lt;- calculate_summary(temp_data, \"T2M\")\n    weather_summary[row_index, c(\"temperature.mean\", \"temperature.sd\", \n                                \"temperature.max\", \"temperature.min\", \n                                \"temperature.error\")] &lt;- temp_summary\n    \n    # Max temperature\n    max_temp_summary &lt;- calculate_summary(temp_data, \"T2M_MAX\")\n    weather_summary[row_index, c(\"maxTemperature.mean\", \"maxTemperature.max\", \n                                \"maxTemperature.min\", \"maxTemperature.error\")] &lt;- max_temp_summary[c(\"mean\", \"max\", \"min\", \"error\")]\n    \n    # Min temperature\n    min_temp_summary &lt;- calculate_summary(temp_data, \"T2M_MIN\")\n    weather_summary[row_index, c(\"minTemperature.mean\", \"minTemperature.max\", \n                                \"minTemperature.min\", \"minTemperature.error\")] &lt;- min_temp_summary[c(\"mean\", \"max\", \"min\", \"error\")]\n    \n    # Temperature deviations\n    lower_dev &lt;- temp_data$T2M - temp_data$T2M_MIN\n    upper_dev &lt;- temp_data$T2M_MAX - temp_data$T2M\n    \n    weather_summary[row_index, \"temperature.lowerDeviation\"] &lt;- mean(lower_dev, na.rm = TRUE)\n    weather_summary[row_index, \"temperature.lowerDeviation.error\"] &lt;- qt(0.975, length(lower_dev) - 1) * \n      sd(lower_dev, na.rm = TRUE) / sqrt(length(lower_dev))\n    \n    weather_summary[row_index, \"temperature.upperDeviation\"] &lt;- mean(upper_dev, na.rm = TRUE)\n    weather_summary[row_index, \"temperature.upperDeviation.error\"] &lt;- qt(0.975, length(upper_dev) - 1) * \n      sd(upper_dev, na.rm = TRUE) / sqrt(length(upper_dev))\n    \n    # Precipitation\n    precip_summary &lt;- calculate_summary(temp_data, \"PRECTOT\")\n    weather_summary[row_index, c(\"precipitation.mean\", \"precipitation.max\", \n                                \"precipitation.min\", \"precipitation.error\")] &lt;- precip_summary[c(\"mean\", \"max\", \"min\", \"error\")]\n    \n    row_index &lt;- row_index + 1\n  }\n}\n\n# Remove any unused rows\nweather_summary &lt;- weather_summary[1:(row_index-1), ]\n\nSet colours for maximum and minimum temperature:\n\nmax_temperature_colour = hsv(7.3/360, 74.6/100, 70/100)\n\nmin_temperature_colour = hsv(232/360, 64.6/100, 73/100)\n\nCreate figure:\n\n# Constants\nYEAR_LENGTH &lt;- 366\nSOLSTICE_SUMMER &lt;- 172  # June 21st (approx.)\nSOLSTICE_WINTER &lt;- 355  # December 21st (approx.)\n\n# Helper functions\nround_to_multiple &lt;- function(x, base, round_fn = round) {\n  round_fn(x / base) * base\n}\n\ncreate_polygon &lt;- function(x, y1, y2, alpha = 0.5, col = \"black\") {\n  polygon(c(x, rev(x)), c(y1, rev(y2)), col = adjustcolor(col, alpha = alpha), border = NA)\n}\n\nplot_weather_variable &lt;- function(x, y, ylim, lwd, col = \"black\", lty = 1) {\n  plot(x, y, axes = FALSE, ylim = ylim, type = \"l\", lwd = lwd, col = col, lty = lty)\n}\n\nadd_confidence_interval &lt;- function(x, y_mean, error, col, alpha = 0.5) {\n  create_polygon(x, y_mean + error, y_mean, alpha, col)\n  create_polygon(x, y_mean - error, y_mean, alpha, col)\n}\n\nadd_min_max_interval &lt;- function(x, y_mean, y_min, y_max, col, alpha = 0.3) {\n  create_polygon(x, y_max, y_mean, alpha, col)\n  create_polygon(x, y_min, y_mean, alpha, col)\n}\n\n# Main plotting function\nplot_weather_summary &lt;- function(weather_summary, sites, sites_latitude, weather) {\n  # Setup plot\n  num_columns &lt;- length(sites) + 1\n  num_rows_except_bottom &lt;- 4\n  \n  layout_matrix &lt;- rbind(\n    matrix(1:(num_columns * num_rows_except_bottom), nrow = num_rows_except_bottom, ncol = num_columns, byrow = FALSE),\n    c((num_columns * num_rows_except_bottom) + 1, rep((num_columns * num_rows_except_bottom) + 2, length(sites)))\n  )\n  \n  layout(layout_matrix,\n         widths = c(3, 12, rep(10, length(sites) - 2), 14),\n         heights = c(3, 10, 10, 12, 2))\n  \n  # Y-axis labels\n  y_labs &lt;- c(expression(paste(\"solar radiation (\", MJ/m^-2, \")\")),\n             \"temperature (C)\", \"precipitation (mm)\")\n  \n  # Calculate ranges\n  range_solar &lt;- c(\n    round_to_multiple(min(weather_summary$solarRadiation.min), 5, floor),\n    round_to_multiple(max(weather_summary$solarRadiationTop.mean), 5, ceiling)\n  )\n  range_temp &lt;- c(\n    round_to_multiple(min(weather_summary$minTemperature.min), 5, floor),\n    round_to_multiple(max(weather_summary$maxTemperature.max), 5, ceiling)\n  )\n  range_precip &lt;- c(\n    round_to_multiple(min(weather_summary$precipitation.min), 5, floor),\n    round_to_multiple(max(weather_summary$precipitation.max), 5, ceiling)\n  )\n  \n  # Plot settings\n  par(cex = graphic_scale, cex.axis = graphic_scale * (0.8 + axis_text_rescale))\n  \n  # First column: y axis titles\n  for (i in 1:4) {\n    par(mar = c(0, 0, 0, 0.4))\n    plot(c(0, 1), c(0, 1), ann = FALSE, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n    if (i &gt; 1) {\n      text(x = 0.5, y = 0.5, font = 4, \n           cex = graphic_scale * (0.78 + font_rescale), \n           srt = 90,\n           labels = y_labs[i-1])\n    }\n  }\n  \n  # Plot for each site\n  for (site in sites) {\n    temp_data &lt;- weather_summary[weather_summary$Site == site,]\n    \n    left_plot_margin &lt;- ifelse(site == sites[1], 2, 0.1)\n    right_plot_margin &lt;- ifelse(site == sites[length(sites)], 4, 0.1)\n    \n    # Site name + latitude\n    par(mar = c(0.2, left_plot_margin, 0.1, right_plot_margin))\n    plot(c(0, 1), c(0, 1), ann = FALSE, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n    text(x = 0.5, y = 0.5, font = 4, \n         cex = graphic_scale * (0.7 + font_rescale),\n         labels = paste(site, sites_latitude$Latitude[sites_latitude$Site == site], sep = \"\\n\"))\n    \n    # Solar radiation\n    par(mar = c(0.1, left_plot_margin, 0.1, right_plot_margin))\n    plot_weather_variable(1:YEAR_LENGTH, temp_data$solarRadiation.mean, range_solar, graphic_scale)\n    add_confidence_interval(1:YEAR_LENGTH, temp_data$solarRadiation.mean, temp_data$solarRadiation.error, \"black\")\n    add_min_max_interval(1:YEAR_LENGTH, temp_data$solarRadiation.mean, temp_data$solarRadiation.min, temp_data$solarRadiation.max, \"black\")\n    lines(1:YEAR_LENGTH, temp_data$solarRadiationTop.mean, lty = 2, lwd = graphic_scale)\n    \n    abline(v = c(SOLSTICE_SUMMER, SOLSTICE_WINTER), lty = 3, lwd = graphic_scale)\n    \n    if (site == sites[1]) {\n      axis(2, at = seq(range_solar[1], range_solar[2], 5))\n    }\n\n    # Temperature\n    plot_weather_variable(1:YEAR_LENGTH, temp_data$temperature.mean, range_temp, graphic_scale)\n    add_confidence_interval(1:YEAR_LENGTH, temp_data$temperature.mean, temp_data$temperature.error, \"black\")\n    add_min_max_interval(1:YEAR_LENGTH, temp_data$temperature.mean, temp_data$temperature.min, temp_data$temperature.max, \"black\")\n    \n    lines(1:YEAR_LENGTH, temp_data$maxTemperature.mean, lwd = graphic_scale, col = max_temperature_colour)\n    add_confidence_interval(1:YEAR_LENGTH, temp_data$maxTemperature.mean, temp_data$maxTemperature.error, col = max_temperature_colour)\n    add_min_max_interval(1:YEAR_LENGTH, temp_data$maxTemperature.mean, temp_data$maxTemperature.min, temp_data$maxTemperature.max, max_temperature_colour)\n    \n    lines(1:YEAR_LENGTH, temp_data$minTemperature.mean, lwd = graphic_scale, col = min_temperature_colour)\n    add_confidence_interval(1:YEAR_LENGTH, temp_data$minTemperature.mean, temp_data$minTemperature.error, min_temperature_colour)\n    add_min_max_interval(1:YEAR_LENGTH, temp_data$minTemperature.mean, temp_data$minTemperature.min, temp_data$minTemperature.max, min_temperature_colour)\n\n    abline(v = c(SOLSTICE_SUMMER, SOLSTICE_WINTER), lty = 3, lwd = graphic_scale)\n    \n    if (site == sites[1]) {\n      axis(2, at = seq(range_temp[1], range_temp[2], 5))\n    }\n\n    # Precipitation\n    par(mar = c(8, left_plot_margin, 0.1, right_plot_margin))\n    plot(c(1, YEAR_LENGTH), c(0, 1), ann = FALSE, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n    \n    for (year in unique(weather$YEAR)) {\n      site_year_data &lt;- weather[weather$Site == site & weather$YEAR == year, ]\n      lines(1:nrow(site_year_data), \n            cumsum(site_year_data$PRECTOT) / sum(site_year_data$PRECTOT), \n            lwd = graphic_scale, \n            col = rgb(0, 0, 0, alpha = 0.2))\n    }\n    \n    if (site == sites[length(sites)]) {\n      axis(4, at = seq(0, 1, 0.25))\n      mtext(\"cumulative annual sum\", 4, line = 2.5, cex = graphic_scale * (1.5 + margin_text_rescale))\n    }\n    \n    par(new = TRUE, mar = c(3, left_plot_margin, 0.1, right_plot_margin))\n    plot_weather_variable(1:YEAR_LENGTH, temp_data$precipitation.mean, range_precip, graphic_scale)\n    add_confidence_interval(1:YEAR_LENGTH, temp_data$precipitation.mean, temp_data$precipitation.error, \"black\")\n    add_min_max_interval(1:YEAR_LENGTH, temp_data$precipitation.mean, temp_data$precipitation.min, temp_data$precipitation.max, \"black\")\n    \n    # Add solstices and axes\n    abline(v = c(SOLSTICE_SUMMER, SOLSTICE_WINTER), lty = 3, lwd = graphic_scale)\n    \n    if (site == sites[1]) {\n      axis(2, at = seq(range_precip[1], range_precip[2], 10))\n    }\n    \n    axis(1, at = cumsum(c(31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31)), las = 2)\n  }\n  \n  # Bottom row: \"day of year\" label\n  par(mar = c(0, 0, 0, 0))\n  plot(c(0, 1), c(0, 1), ann = FALSE, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n  plot(c(0, 1), c(0, 1), ann = FALSE, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n  text(x = 0.5, y = 0.7, font = 4, \n       cex = graphic_scale * (0.8 + font_rescale),\n       labels = \"day of year\")\n}\n\n# Main execution\nplot_name &lt;- file.path(output_dir, paste0(\"Fig1-annualWeatherVariablesExamples.\", plot_file_format))\n\nif (plot_file_format == \"png\") {\n  graphic_scale &lt;- 2\n  font_rescale &lt;- axis_text_rescale &lt;- margin_text_rescale &lt;- 0\n\n  png(plot_name, width = number_of_sites * graphic_scale * 150, height = graphic_scale * 800)\n} else if (plot_file_format == \"eps\") {\n  graphic_scale = 1.2\n  font_rescale = 0.1\n  axis_text_rescale = -0.1\n  margin_text_rescale = -0.5\n\n  extrafont::loadfonts(device = \"postscript\")\n  grDevices::cairo_ps(filename = plot_name ,\n                      pointsize = 12,\n                      width = number_of_sites * graphic_scale * 1.5,\n                      height = graphic_scale * 8,\n                      onefile = FALSE,\n                      family = \"sans\"\n                      )\n}\nplot_weather_summary(weather_summary, sites, sites_latitude, weather)\ndev.off()\n\nsvg \n  2 \n\n\n\nknitr::include_graphics(plot_name)\n\n\n\n\n\n\n\n\nCompute annual precipitation for each site and year:\n\n# Initialize the result data frame\nannual_precipitation &lt;- data.frame(\n  Site = character(),\n  year = numeric(),\n  precipitation.annual = numeric(),\n  stringsAsFactors = FALSE\n)\n\n# Compute annual precipitation\nfor (site in sites) {\n  for (year in years) {\n    temp_data &lt;- subset(weather, Site == site & YEAR == year)\n    temp_data &lt;- sum(temp_data$PRECTOT, na.rm = TRUE)\n    \n    annual_precipitation &lt;- rbind(annual_precipitation, \n                                 data.frame(Site = site, \n                                            year = as.numeric(year), \n                                            precipitation.annual = temp_data))\n  }\n}\n\n# Clean up\nrm(temp_data)\n\n\n# Perform normality tests\nnormality_test_per_site &lt;- lapply(sites, function(site) {\n  site_data &lt;- subset(annual_precipitation, Site == site)\n  shapiro.test(site_data$precipitation.annual)\n})\nnames(normality_test_per_site) &lt;- sites\n\n# Display results\nprint(head(annual_precipitation))\n\n     Site year precipitation.annual\n1 Irkutsk 1984               571.51\n2 Irkutsk 1985               527.76\n3 Irkutsk 1986               528.28\n4 Irkutsk 1987               599.30\n5 Irkutsk 1988               540.49\n6 Irkutsk 1989               349.27\n\nprint(normality_test_per_site)\n\n$Irkutsk\n\n    Shapiro-Wilk normality test\n\ndata:  site_data$precipitation.annual\nW = 0.95701, p-value = 0.3813\n\n\n$Cambridge\n\n    Shapiro-Wilk normality test\n\ndata:  site_data$precipitation.annual\nW = 0.98817, p-value = 0.9901\n\n\n$Rakhigarhi\n\n    Shapiro-Wilk normality test\n\ndata:  site_data$precipitation.annual\nW = 0.94736, p-value = 0.2373\n\n\n$`Pearl Harbor`\n\n    Shapiro-Wilk normality test\n\ndata:  site_data$precipitation.annual\nW = 0.90829, p-value = 0.03239\n\n\n$Windhoek\n\n    Shapiro-Wilk normality test\n\ndata:  site_data$precipitation.annual\nW = 0.93145, p-value = 0.105\n\n\n$`Sao Paulo`\n\n    Shapiro-Wilk normality test\n\ndata:  site_data$precipitation.annual\nW = 0.94245, p-value = 0.1849\n\n\n$Hobart\n\n    Shapiro-Wilk normality test\n\ndata:  site_data$precipitation.annual\nW = 0.9853, p-value = 0.9704\n\n\nCreate figure:\n\n# Helper functions\nround_to_multiple &lt;- function(x, base, round_fn = round) {\n  round_fn(x / base) * base\n}\n\nplot_empty &lt;- function() plot(c(0, 1), c(0, 1), ann = FALSE, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n\nplot_y_axis_title &lt;- function(label, x = 0.3, y = 0.5) {\n  plot_empty()\n  text(x = x, y = y, labels = label, srt = 90, font = 1, cex = graphic_scale * (0.78 + font_rescale))\n}\n\nplot_x_axis_title &lt;- function(label, x = 0.5, y = 0.3) {\n  plot_empty()\n  text(x = x, y = y, labels = label, font = 4, \n       cex = graphic_scale * (0.78 + font_rescale))\n}\n\nplot_annualprecip_series &lt;- function(precip_annual_dataframe, precip_annual_mean, precip_range, site_label, is_last){\n  # Plot annual precipitation series\n  par(mar = c(ifelse(is_last, 1, 0.2), 0.1, 0.1, 0.1))\n  \n  plot(precip_annual_dataframe$year, precip_annual_dataframe$precipitation.annual,\n       ylim = precip_range + c(-0.1, 0.1) * diff(precip_range),\n       type = 'l', lty = 1, lwd = graphic_scale, col = \"black\", xaxt = 'n', yaxt = 'n')\n  \n  # Add colored polygons\n  polygon(c(precip_annual_dataframe$year, rev(precip_annual_dataframe$year)),\n          c(pmax(precip_annual_dataframe$precipitation.annual, precip_annual_mean),\n            rep(precip_annual_mean, nrow(precip_annual_dataframe))),\n          col = rgb(0, 0, 0.8, alpha = 0.3), border = NA)\n  polygon(c(precip_annual_dataframe$year, rev(precip_annual_dataframe$year)),\n          c(pmin(precip_annual_dataframe$precipitation.annual, precip_annual_mean),\n            rep(precip_annual_mean, nrow(precip_annual_dataframe))),\n          col = rgb(0.8, 0, 0, alpha = 0.3), border = NA)\n  \n  abline(h = precip_annual_mean, lty = 2, col = \"darkgrey\")\n  \n  # Add site label and axes\n  text(x = precip_annual_dataframe$year[1] - 0.03 * number_of_years,\n       y = precip_range[1] + 0.04 * diff(precip_range),\n       labels = site_label, cex = graphic_scale * (0.8 + font_rescale), adj = 0)\n  \n  axis(2, at = seq(precip_range[1], precip_range[2], by = 50))\n  if (is_last) axis(1, at = years)\n}\n\nplot_hist_and_normal &lt;- function(precipitation_annual, is_last) {\n  # Plot histogram, normal density model and Shapiro-Wilk test results\n  par(mar = c(ifelse(is_last, 1, 0.2), 0.1, 0.1, 0.5))\n\n  hist_data &lt;- hist(precipitation_annual, breaks = 8, plot = FALSE)\n\n  plot(hist_data$density, hist_data$mids, type = \"s\", lwd = 2, col = \"lightblue\", xaxt = 'n', yaxt = 'n')\n  \n  # Add normal curve\n  normal_curve &lt;- dnorm(\n    hist_data$mids, \n    mean = mean(precipitation_annual, na.rm = TRUE), \n    sd = sd(precipitation_annual, na.rm = TRUE))\n  lines(normal_curve, hist_data$mids,\n        col = \"red\", lwd = 2)\n  \n  # Add Shapiro-Wilk test results\n  sw_test &lt;- shapiro.test(precipitation_annual)\n  text(x = 0.99 * max(hist_data$density),\n       y = hist_data$breaks[1] + 0.85 * diff(range(hist_data$breaks)),\n       labels = sprintf(\"W = %.4f\\n p = %.4f%s\", \n                        sw_test$statistic, sw_test$p.value,\n                        ifelse(sw_test$p.value &gt; 0.05, \"*\", \"\")),\n       cex = graphic_scale * (0.7 + font_rescale), adj = 1)\n}\n\n# Main plotting function\nplot_annualprecip_summary &lt;- function(annual_precipitation, sites, number_of_sites) {\n  # Set up layout\n  layout_matrix &lt;- matrix(3:((2 * number_of_sites) + 4), nrow = number_of_sites + 1, ncol = 2, byrow = TRUE)\n\n  layout_matrix &lt;- cbind(c(rep(1, number_of_sites), 2), layout_matrix)\n\n  layout(layout_matrix, widths = c(1, 12, 5), heights = c(rep(10, number_of_sites), 3))\n\n  # Set global parameters\n  par(cex = graphic_scale, cex.axis = graphic_scale * (0.8 + axis_text_rescale))\n\n  # Plot y-axis label\n  par(mar = c(0, 0, 0, 0.4))\n  plot_y_axis_title(\"annual precipitation (mm)\")\n  plot_empty()\n\n  # Plot precipitation lines and histograms\n  for (site in sites) {\n  \n    temp_data &lt;- subset(annual_precipitation, Site == site)\n    site_precipitation_mean &lt;- mean(temp_data$precipitation.annual)\n    is_last &lt;- (site == sites[length(sites)])\n  \n    # Calculate plot ranges\n    temp_range &lt;- range(temp_data$precipitation.annual)\n    temp_range &lt;- round_to_multiple(temp_range, 10)\n  \n    # left plot\n    plot_annualprecip_series(temp_data, site_precipitation_mean, temp_range, site, is_last)\n  \n    # right plot\n    plot_hist_and_normal(temp_data$precipitation.annual, is_last)\n  \n    #if (is_last) axis(1, at = seq(0, round(max(hist_data$density), digits = 4), length.out = 5))\n  }\n# Plot x-axis labels\nplot_x_axis_title(\"year\")\nplot_x_axis_title(\"frequency\", y = 0.7)\n}\n\n# Main execution\n\nplot_name &lt;- file.path(output_dir, paste0(\"Fig2-annualPrecipitationExamples.\", plot_file_format))\n\n# Set up plot parameters and open device\nif (plot_file_format == \"png\") {\n  graphic_scale &lt;- 2\n  font_rescale &lt;- axis_text_rescale &lt;- margin_text_rescale &lt;- 0\n  png(plot_name, width = number_of_years * graphic_scale * 50, height = graphic_scale * number_of_sites * 200)\n} else if (plot_file_format == \"eps\") {\n  graphic_scale &lt;- 2\n  font_rescale &lt;- 0.2\n  axis_text_rescale &lt;- 0.2\n  margin_text_rescale &lt;- 0.2\n  grDevices::cairo_ps(filename = plot_name, pointsize = 12,\n                      width = number_of_years * graphic_scale * 1,\n                      height = number_of_sites * graphic_scale * 4,\n                      onefile = FALSE, family = \"sans\")\n}\nplot_annualprecip_summary(annual_precipitation, sites, number_of_sites)\ndev.off()\n\nsvg \n  2 \n\n\n\nknitr::include_graphics(plot_name)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Daily weather in example locations</span>"
    ]
  },
  {
    "objectID": "full-model-example.html",
    "href": "full-model-example.html",
    "title": "3  Example of simulation outputs of the Weather model for 5 years",
    "section": "",
    "text": "Choose file format for generated figures:\n\noutput_dir &lt;- \"output\"\nplot_file_format &lt;- c(\"png\", \"eps\")[1] # modify index number to change format\n\nLoad source file containing the R implementation of the Weather model:\n\nsource(\"source/weatherModel.R\")\n\nInitialisation using the default parametrisation, based on data from Rakhigarhi (example location, see Fig. 1):\n\nSEED &lt;- 0\nYEAR_LENGTH &lt;- 365 # ignoring leap year adjustment\nNUM_YEARS &lt;- 5\nNUM_DAYS &lt;- NUM_YEARS * YEAR_LENGTH\n\nweather_model &lt;- initialise_weather_model(seed = SEED, year_length = YEAR_LENGTH)\n\nShow table with parameter values:\n\nsource(\"source/extract_params.R\")\n\n# Extract initial parameters\ninitial_params &lt;- list(\n  names = c(\"seed\", \"year_length\", \"albedo\", \"southern_hemisphere\"),\n  values = unlist(weather_model$PARAMS[1:4])\n)\n\n# Extract remaining parameters\nremaining_params &lt;- lapply(names(weather_model$PARAMS)[5:length(weather_model$PARAMS)], \n                           function(name) extract_params(weather_model$PARAMS[[name]], name))\n\n# Combine all parameters\nall_params &lt;- list(\n  names = c(initial_params$names, unlist(lapply(remaining_params, `[[`, \"names\"))),\n  values = c(initial_params$values, unlist(lapply(remaining_params, `[[`, \"values\")))\n)\n\n# Create the table\nparams_values &lt;- cbind(all_params$names, all_params$values)\nrow.names(params_values) &lt;- NULL\nknitr::kable(params_values, \n             format = \"html\",\n             col.names = c(\"parameter\", \"values\"),\n             align = c(\"l\", \"r\"))\n\n\n\n\n\nparameter\nvalues\n\n\n\n\nseed\n0\n\n\nyear_length\n365\n\n\nalbedo\n0.4\n\n\nsouthern_hemisphere\n0\n\n\ntemperature - annual_max\n40\n\n\ntemperature - annual_min\n15\n\n\ntemperature - daily_fluctuation\n5\n\n\ntemperature - daily_lower_dev\n5\n\n\ntemperature - daily_upper_dev\n5\n\n\nsolar - annual_max\n7\n\n\nsolar - annual_min\n3\n\n\nsolar - daily_fluctuation\n1\n\n\nprecipitation - annual_sum_mean\n400\n\n\nprecipitation - annual_sum_sd\n130\n\n\nprecipitation - plateau_value_mean\n0.1\n\n\nprecipitation - plateau_value_sd\n0.05\n\n\nprecipitation - inflection1_mean\n40\n\n\nprecipitation - inflection1_sd\n20\n\n\nprecipitation - rate1_mean\n0.15\n\n\nprecipitation - rate1_sd\n0.02\n\n\nprecipitation - inflection2_mean\n200\n\n\nprecipitation - inflection2_sd\n20\n\n\nprecipitation - rate2_mean\n0.05\n\n\nprecipitation - rate2_sd\n0.01\n\n\nprecipitation - n_samples_mean\n200\n\n\nprecipitation - n_samples_sd\n5\n\n\nprecipitation - max_sample_size_mean\n10\n\n\nprecipitation - max_sample_size_sd\n3\n\n\n\n\n\n\n\n\nRun model:\n\nweather_model &lt;- run_weather_model(weather_model, num_years = NUM_YEARS)\n\nSet colours for maximum and minimum temperature:\n\nmax_temperature_colour = hsv(7.3/360, 74.6/100, 70/100)\n\nmin_temperature_colour = hsv(232/360, 64.6/100, 73/100)\n\nPlot time-series:\n\n# Helper functions\nplot_solar_radiation &lt;- function(solar_radiation, num_days, year_length) {\n    plot(1:num_days, solar_radiation, \n         type = \"l\", xlab = \"\", xaxt = 'n', ylab = \"\")\n    mark_end_years(num_days, year_length = year_length)\n}\n\nplot_temperature &lt;- function(temperature, max_temperature_colour, min_temperature_colour, num_days, year_length) {\n    plot(1:num_days, temperature, \n         type = \"l\", xlab = \"\", xaxt = 'n', ylab = \"\",\n         ylim = c(floor(min(weather_model$daily$temperature_min)), \n                  ceiling(max(weather_model$daily$temperature_max))))\n    lines(1:num_days, weather_model$daily$temperature_max, \n          col = adjustcolor(max_temperature_colour, alpha.f = 0.8))\n    lines(1:num_days, weather_model$daily$temperature_min, \n          col = adjustcolor(min_temperature_colour, alpha.f = 0.8))\n    mark_end_years(num_days, year_length = year_length)\n}\n\nplot_ETr &lt;- function(ETr, num_days, year_length) {\n    plot(1:num_days, weather_model$daily$ETr, type = \"l\",\n         ylab = \"\", xlab = \"\", xaxt = 'n')\n    mark_end_years(num_days, year_length = year_length)\n}\n\nplot_precipitation &lt;- function(precipitation, num_days, year_length) {\n    par(mar = c(2, 1, 0.1, 0.1))\n    barplot(weather_model$daily$precipitation, \n            ylab = \"\", xlab = \"\", xaxt = 'n')\n    mark_end_years(num_days, year_length = year_length, offset = 1.2)\n    abline(v = num_days * 1.2, lty = 3)\n}\n\nplot_time_axis &lt;- function(num_days, graphic_scale, font_rescale, margin_text_rescale) {\n    par(mar = c(1, 1, 0, 0.1))\n    plot(c(1, num_days), c(0, 1), ann = FALSE, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n    axis(3, at = 1:num_days, tck = 0, lwd = 0)\n    mtext(\"day\", side = 1, line = -1,\n          font = 4, cex = graphic_scale * (1.7 + font_rescale + margin_text_rescale))\n}\n\n# Main plotting function\nplot_weather_simulation &lt;- function(weather_model, num_days, year_length, graphic_scale, font_rescale, axis_text_rescale, margin_text_rescale, max_temperature_colour, min_temperature_colour) {\n    layout(matrix(c(1:10), \n                  nrow = 5, ncol = 2, byrow = FALSE), \n           widths = c(1, 10),\n           heights = c(10, 10, 10, 12, 2))\n\n    y_labs &lt;- c(expression(paste(\n        \"    Solar\\nRadiation (\", MJ/m^-2, \")\")), \n        \"Temperature (C)\", \"ETr (mm)\", \"Precipitation (mm)\")\n\n    par(cex = graphic_scale)\n\n    # First column\n    par(mar = c(0, 0, 0, 0))\n    for (i in 1:4) {\n        plot(c(0, 1), c(0, 1), ann = FALSE, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n        text(x = 0.5, y = 0.5 + (i &gt; 2) * 0.1, font = 4, \n             cex = graphic_scale * (0.6 + 0.1 * (i &gt; 1) + font_rescale), \n             srt = 90,\n             labels = y_labs[i])\n    }\n    plot(c(0, 1), c(0, 1), ann = FALSE, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n\n    # Second column\n    par(mar = c(0.2, 1, 0.5, 0.1), cex.axis = graphic_scale * (0.6 + axis_text_rescale))\n\n    # 1: Solar radiation\n    plot_solar_radiation(weather_model$daily$solar_radiation, num_days = num_days, year_length = year_length)\n    # 2: Temperature\n    plot_temperature(weather_model$daily$temperature, num_days = num_days, year_length = year_length, \n                     max_temperature_colour = max_temperature_colour, min_temperature_colour = min_temperature_colour)\n    # 3: Reference evapotranspiration\n    plot_ETr(weather_model$daily$ETr, num_days = num_days, year_length = year_length)\n    # 4: Precipitation\n    plot_precipitation(weather_model$daily$precipitation, num_days = NUM_DAYS, year_length = year_length)\n    \n    # 5: x-axis title\n    plot_time_axis(num_days = num_days, graphic_scale = graphic_scale, font_rescale = font_rescale, margin_text_rescale = margin_text_rescale)\n}\n\n# Main execution\nplot_name &lt;- file.path(output_dir, paste0(\"Fig3-weather_modelExample.\", plot_file_format))\n    \nif (plot_file_format == \"png\") {\n  graphic_scale &lt;- 2\n  font_rescale &lt;- axis_text_rescale &lt;- margin_text_rescale &lt;- 0\n  png(plot_name, width = graphic_scale * 600, height = graphic_scale * 700)\n} else if (plot_file_format == \"eps\") {\n  graphic_scale &lt;- 1.2\n  font_rescale &lt;- 0.1\n  axis_text_rescale &lt;- -0.1\n  margin_text_rescale &lt;- -0.5\n  extrafont::loadfonts(device = \"postscript\")\n  grDevices::cairo_ps(filename = plot_name, pointsize = 12,\n                      width = graphic_scale * 6, height = graphic_scale * 7,\n                      onefile = FALSE, family = \"sans\")\n} else {\n  stop(\"Unsupported file format\")\n}\n\nplot_weather_simulation(weather_model, num_days = NUM_DAYS, year_length = YEAR_LENGTH, \n                        graphic_scale = graphic_scale, font_rescale = font_rescale, \n                        axis_text_rescale = axis_text_rescale, margin_text_rescale = margin_text_rescale, \n                        max_temperature_colour = max_temperature_colour, min_temperature_colour = min_temperature_colour)\ndev.off()\n\nsvg \n  2 \n\n\n\nknitr::include_graphics(plot_name)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Example of simulation outputs of the Weather model for 5 years</span>"
    ]
  },
  {
    "objectID": "annual-sinusoid-curve-parameters.html",
    "href": "annual-sinusoid-curve-parameters.html",
    "title": "4  Demonstration of parameter variation: solar radiation and temperature",
    "section": "",
    "text": "Choose file format for generated figures:\n\noutput_dir &lt;- \"output\"\nplot_file_format &lt;- c(\"png\", \"eps\")[1] # modify index number to change format\n\nLoad source file containing the R implementation of the Weather model:\n\nsource(\"source/weatherModel.R\")\n\nSet up six variations of parameter settings (i.e. min_value, max_value, is_south_hemisphere), assuming length of year of 365 days:\n\nSEED &lt;- 0\nYEAR_LENGTH &lt;- 365\nis_southern_hemisphere_values &lt;- c(FALSE, TRUE)\n\npar_values_annual_sinusoid &lt;- matrix(\n  c(0.1, 1.5, 0.31,\n    -0.5, 3.3, 0.73,\n    1.5, 2.7, 0.06,\n    2.1, 4.2, 0.25,\n    -1.6, 5, 1,\n    4, 4.5, 0.02),\n  ncol = 3, byrow = TRUE\n)\n\nmin_min_value &lt;- min(par_values_annual_sinusoid[,1] - par_values_annual_sinusoid[,3])\nmax_max_value &lt;- max(par_values_annual_sinusoid[,2] + par_values_annual_sinusoid[,3])\n\nnum_runs &lt;- nrow(par_values_annual_sinusoid)\n\nCreate a colour palette for plotting:\n\nnum_cold_colours &lt;- num_runs %/% 2\nnum_warm_colours &lt;- num_runs - num_cold_colours\n\ncreate_color_sequence &lt;- function(start, end, n) {\n  seq(start, end, length.out = n)\n}\n\ncreate_color_values &lt;- function(h_range, s_range, v_range, n) {\n  cbind(\n    h = create_color_sequence(h_range[1], h_range[2], n) / 360,\n    s = create_color_sequence(s_range[1], s_range[2], n) / 100,\n    v = create_color_sequence(v_range[1], v_range[2], n) / 100\n  )\n}\n\ncolor_palette_values &lt;- rbind(\n  create_color_values(c(198.6, 299.4), c(61.6, 75.3), c(95.2, 76.4), num_cold_colours),\n  create_color_values(c(5.15, 67.5), c(67, 77.8), c(73.7, 86.4), num_warm_colours)\n)\n\ncolor_palette &lt;- apply(color_palette_values, 1, function(x) hsv(x[1], x[2], x[3]))\n\nPlot curves:\n\n# Helper functions\nplot_empty &lt;- function() {\n  plot(c(0, 1), c(0, 1), ann = FALSE, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n}\n\nadd_text &lt;- function(x, y, label, cex_factor = 0.6, srt = 0) {\n  text(x = x, y = y, labels = label, font = 4, \n       cex = graphic_scale * (cex_factor + font_rescale), srt = srt)\n}\n\n# Main plotting function\nplot_annual_sinusoid &lt;- function(par_values_annual_sinusoid, is_southern_hemisphere_values, min_min_value, max_max_value) {\n  layout(matrix(c(1,  2,  3, 12,\n                  4,  5,  6, 12,\n                  7,  8,  9, 12,\n                  10, 11, 11, 12),\n                nrow = 4, ncol = 4, byrow = TRUE),\n         widths = c(1, 10, 10, 6),\n         heights = c(2, 10, 10, 2))\n\n  par(cex = graphic_scale * 1.2, mar = c(0, 0, 0, 0))\n\n  # Titles\n  plot_empty()\n  for (hemisphere in c(\"FALSE\", \"TRUE\")) {\n    plot_empty()\n    add_text(0.55, 0.5, paste(\"southern_hemisphere =\", hemisphere))\n  }\n\n  # Y-axis titles and plots\n  plot_empty()\n  add_text(0.5, 0.5, \"annual sinusoidal curve\", srt = 90)\n  \n  par(mar = c(2, 2, 0.1, 0.1))\n  \n  for (is_southern_hemisphere in is_southern_hemisphere_values) {\n    plot(c(1, YEAR_LENGTH), c(min_min_value, max_max_value), type = \"n\", xlab = \"\", ylab = \"\")\n    \n    for (i in 1:nrow(par_values_annual_sinusoid)) {\n      curve &lt;- gen_annual_sinusoid(\n        min_value = par_values_annual_sinusoid[i, 1],\n        max_value = par_values_annual_sinusoid[i, 2],\n        year_length = YEAR_LENGTH,\n        is_southern_hemisphere = is_southern_hemisphere)\n      \n      lines(1:length(curve), curve, col = color_palette[i], lwd = graphic_scale * 3)\n    }\n  }\n\n  # Fluctuations\n  par(mar = c(0, 0, 0, 0))\n\n  plot_empty()\n  add_text(0.5, 0.5, \"annual sinusoidal curve\\nwith fluctuations\", cex_factor = 0.5, srt = 90)\n\n  par(mar = c(2, 2, 0.1, 0.1))\n  \n  for (is_southern_hemisphere in is_southern_hemisphere_values) {\n    plot(c(1, YEAR_LENGTH), c(min_min_value, max_max_value), type = \"n\", xlab = \"\", ylab = \"\")\n    \n    for (i in 1:nrow(par_values_annual_sinusoid)) {\n      curve &lt;- gen_annual_sinusoid_with_fluctuation(\n        min_value = par_values_annual_sinusoid[i, 1],\n        max_value = par_values_annual_sinusoid[i, 2],\n        year_length = YEAR_LENGTH,\n        is_southern_hemisphere = is_southern_hemisphere,\n        fluctuation = par_values_annual_sinusoid[i, 3],\n        seed = SEED\n      )\n      \n      lines(1:length(curve), curve, col = color_palette[i], lwd = graphic_scale * 1)\n    }\n  }\n\n  par(mar = c(0, 0, 0, 0))\n\n  # X-axis title\n  plot_empty()\n  plot_empty()\n  add_text(0.5, 0.4, \"day of year\")\n\n  # Legend\n  plot(c(0, 1), c(0, nrow(par_values_annual_sinusoid) + 1), ann = F, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n  x_pos &lt;- 0.25\n  y_pos &lt;- c(0.5, 0.1, -0.1)\n  jump &lt;- 1\n\n  for (i in 1:nrow(par_values_annual_sinusoid)) {\n    legend(x = 0, y = (y_pos[1] + jump * i),\n           legend = substitute(paste(\"min_value = \", minValue, \",\"),\n                               list(minValue = par_values_annual_sinusoid[i, 1])),\n           col = color_palette[i], lwd = graphic_scale * 6,\n           cex = graphic_scale * (0.5 + font_rescale), bty = \"n\")\n    \n    text(x = x_pos, y = (y_pos[2] + jump * i),\n         labels = substitute(paste(\"max_value = \", max_value, \",\"),\n                             list(max_value = par_values_annual_sinusoid[i, 2])),\n         cex = graphic_scale * (0.5 + font_rescale), adj = 0)\n    \n    text(x = x_pos, y = (y_pos[3] + jump * i),\n         labels = substitute(paste(\"fluctuation = \", fluctuation),\n                             list(fluctuation = par_values_annual_sinusoid[i, 3])),\n         cex = graphic_scale * (0.5 + font_rescale), adj = 0)\n  }\n}\n\n# Main execution\nplot_name &lt;- file.path(output_dir, paste0(\"Fig4-annualSinusoidCurve.\", plot_file_format))\n\nif (plot_file_format == \"png\") {\n  graphic_scale &lt;- 2\n  font_rescale &lt;- axis_text_rescale &lt;- margin_text_rescale &lt;- 0\n  png(plot_name, width = graphic_scale * 1000, height = graphic_scale * 600)\n} else if (plot_file_format == \"eps\") {\n  graphic_scale &lt;- 1.2\n  font_rescale &lt;- 0.1\n  axis_text_rescale &lt;- -0.1\n  margin_text_rescale &lt;- -0.5\n  extrafont::loadfonts(device = \"postscript\")\n  grDevices::cairo_ps(filename = plot_name, pointsize = 12,\n                      width = graphic_scale * 10, height = graphic_scale * 6,\n                      onefile = FALSE, family = \"sans\")\n}\nplot_annual_sinusoid(par_values_annual_sinusoid, is_southern_hemisphere_values, min_min_value, max_max_value)\ndev.off()\n\nsvg \n  2 \n\n\n\nknitr::include_graphics(plot_name)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Demonstration of parameter variation: solar radiation and temperature</span>"
    ]
  },
  {
    "objectID": "precipitation-parameters.html",
    "href": "precipitation-parameters.html",
    "title": "5  Demonstration of parameter variation: precipitation",
    "section": "",
    "text": "Choose file format for generated figures:\n\noutput_dir &lt;- \"output\"\nplot_file_format &lt;- c(\"png\", \"eps\")[1] # modify index number to change format\n\nLoad source file containing the R implementation of the Weather model:\n\nsource(\"source/weatherModel.R\")\n\nSet up six variations of parameter settings for the annual double logistic curve, discretisation, and annual precipitation, assuming a year length of 365 days. The random generator SEED used in discretisation is fixed:\n\nSEED &lt;- 0\nYEAR_LENGTH &lt;- 365\n\n# Function to create parameter matrix\ncreate_param_matrix &lt;- function(x, ncol, nrow) {\n  matrix(x, ncol = ncol, nrow = nrow, byrow = TRUE)\n}\n\n# Double logistic curve parameters\npar_values_double_logistic &lt;- create_param_matrix(c(\n  0.01, 125, 0.3,  245, 0.22,\n  0.15, 63,  0.55, 195, 0.6,\n  0.5,  64,  0.05, 261, 0.12,\n  0.45, 215, 0.01, 276, 0.39,\n  0.6,  20,  0.38, 254, 0.04,\n  0.85, 97,  0.24, 219, 0.17\n  ), ncol = 5, nrow = 6 \n)\ncolnames(par_values_double_logistic) &lt;- c(\"plateau_value\", \"inflection1\", \"rate1\", \"inflection2\", \"rate2\")\n\n# Discretisation parameters\npar_values_discretisation &lt;- create_param_matrix(c(\n  152, 22,\n  220, 10,\n  240, 6,\n  168, 13,\n  191, 9,\n  205, 17\n  ), ncol = 2, nrow = 6\n)\ncolnames(par_values_discretisation) &lt;- c(\"n_samples\", \"max_sample_size\")\n\nannual_sum_values &lt;- c(410, 1050, 636, 320, 1280, 745)\n\nnum_runs &lt;- nrow(par_values_double_logistic)\n\nCreate a colour palette for plotting:\n\nnum_cold_colours &lt;- num_runs %/% 2\nnum_warm_colours &lt;- num_runs - num_cold_colours\n\ncreate_color_sequence &lt;- function(start, end, n) {\n  seq(start, end, length.out = n)\n}\n\ncreate_color_values &lt;- function(h_range, s_range, v_range, n) {\n  cbind(\n    h = create_color_sequence(h_range[1], h_range[2], n) / 360,\n    s = create_color_sequence(s_range[1], s_range[2], n) / 100,\n    v = create_color_sequence(v_range[1], v_range[2], n) / 100\n  )\n}\n\ncolor_palette_values &lt;- rbind(\n  create_color_values(c(198.6, 299.4), c(61.6, 75.3), c(95.2, 76.4), num_cold_colours),\n  create_color_values(c(5.15, 67.5), c(67, 77.8), c(73.7, 86.4), num_warm_colours)\n)\n\ncolor_palette &lt;- apply(color_palette_values, 1, function(x) hsv(x[1], x[2], x[3]))\n\nPlot curves:\n\n# Helper functions\ncreate_data_frame &lt;- function(rows, cols) {\n  data.frame(matrix(0, nrow = rows, ncol = cols))\n}\n\ncreate_plot &lt;- function(x_range, y_range, ...) {\n  plot(x_range, y_range, type = \"n\", xlab = \"\", ylab = \"\", ...)\n}\n\nadd_text &lt;- function(x, y, label, ...) {\n  text(x = x, y = y, labels = label, ...)\n}\n\ndraw_curve &lt;- function(curve, color, ...) {\n  lines(1:length(curve), curve, col = color, ...)\n}\n\ndraw_points &lt;- function(x, y, color, ...) {\n  points(x, y, col = color, ...)\n}\n\n# Main plotting function\nplot_annual_double_logistic &lt;- function(par_values_double_logistic, par_values_discretisation, annual_sum_values) {\n  \n  # Create data frames\n  double_logistic_curves &lt;- create_data_frame(YEAR_LENGTH, num_runs)\n  discretised_double_logistic_curves &lt;- create_data_frame(YEAR_LENGTH, num_runs)\n  daily_precipitation &lt;- create_data_frame(YEAR_LENGTH, num_runs)\n\n  # Layout setup\n  layout_matrix &lt;- matrix(c(14, 14, 14, 14, 14, 17, 17,\n                            1,   5,  5,  5,  5, 17, 17,\n                            15, 15, 15, 15, 15, 17, 17,\n                            2,   6,  6,  6,  6, 17, 17,\n                            16, 16, 16, 16, 16, 17, 17,\n                            3,   7,  8,  9, 10, 11, 12,\n                            4,  13, 13, 13, 13, 13, 13), \n                          nrow = 7, ncol = 7, byrow = TRUE)\n  layout(layout_matrix, \n         widths = c(2, rep(10, 6)),\n         heights = c(4, 12, 4, 12, 4, 12, 1))\n\n  par(mgp = c(3, 0.4, 0), tcl = -0.4, cex = graphic_scale * 1.2)\n\n  # Y-axis titles\n  y_axis_titles &lt;- c(\"daily cumulative value\", \"daily cumulative value\", \"daily increment\")\n  for (i in 1:3) {\n    par(mar = c(0, 0, 0, 0))\n    create_plot(c(0, 1), c(0, 1), ann = FALSE, bty = 'n', xaxt = 'n', yaxt = 'n')\n    add_text(0.5, 0.5, y_axis_titles[i], font = 4, \n             cex = graphic_scale * (0.7 + font_rescale), srt = 90)\n  }\n\n  # Empty plot\n  create_plot(c(0, 1), c(0, 1), ann = FALSE, bty = 'n', xaxt = 'n', yaxt = 'n')\n\n  # Double logistic curves plot\n  par(mar = c(1, 1, 0.1, 1), cex.axis = graphic_scale * (0.5 + font_rescale))\n  create_plot(c(1, YEAR_LENGTH), c(0, 1))\n\n  for (i in 1:nrow(par_values_double_logistic)) {\n    curve &lt;- gen_annual_double_logistic_curve(\n      plateau_value = par_values_double_logistic[i, 1], \n      inflection1 = par_values_double_logistic[i, 2], \n      rate1 = par_values_double_logistic[i, 3], \n      inflection2 = par_values_double_logistic[i, 4],\n      rate2 = par_values_double_logistic[i, 5],\n      year_length = YEAR_LENGTH)\n    \n    draw_curve(curve, color_palette[i], lwd = graphic_scale * 3)\n    draw_points(c(par_values_double_logistic[i, 2], par_values_double_logistic[i, 4]), \n                c(curve[par_values_double_logistic[i, 2]], curve[par_values_double_logistic[i, 4]]),\n                color_palette[i], pch = 19)\n    \n    double_logistic_curves[,i] &lt;- curve\n  }\n\n  # Discretised double logistic plot\n  create_plot(c(1, YEAR_LENGTH), c(0, 1))\n\n  for (i in 1:nrow(par_values_double_logistic)) {\n    curve &lt;- discretise_curve(\n      curve = double_logistic_curves[,i],\n      n_samples = par_values_discretisation[i, 1],\n      max_sample_size = par_values_discretisation[i, 2],\n      seed = SEED)\n    \n    draw_curve(curve, adjustcolor(color_palette[i], alpha.f = 0.5), lwd = graphic_scale * 3)\n    draw_points(c(par_values_double_logistic[i, 2], par_values_double_logistic[i, 4]), \n                c(curve[par_values_double_logistic[i, 2]], curve[par_values_double_logistic[i, 4]]),\n                adjustcolor(color_palette[i], alpha.f = 0.5), pch = 19)\n    \n    curve &lt;- rescale_curve(curve)\n    \n    draw_curve(curve, color_palette[i], lwd = graphic_scale * 3)\n    draw_points(c(par_values_double_logistic[i, 2], par_values_double_logistic[i, 4]), \n                c(curve[par_values_double_logistic[i, 2]], curve[par_values_double_logistic[i, 4]]),\n                color_palette[i], pch = 19)\n    \n    discretised_double_logistic_curves[,i] &lt;- curve\n  }\n\n  # Daily precipitation plots\n  par(mar = c(2, 1, 0.1, 1), cex.axis = graphic_scale * (0.35 + axis_text_rescale))\n\n  daily_precipitation &lt;- sapply(1:nrow(par_values_double_logistic), function(i) {\n    get_increments_from_cumulative_curve(discretised_double_logistic_curves[,i]) * annual_sum_values[i]\n  })\n\n  maxdaily_precipitation &lt;- max(daily_precipitation)\n\n  for (i in nrow(par_values_double_logistic):1) {\n    barplot(daily_precipitation[,i], \n            names.arg = c(\"1\", rep(NA, 98), \"100\", rep(NA, 99), \"200\", rep(NA, 99), \"300\", rep(NA, 65)),\n            ylim = c(0, maxdaily_precipitation),\n            col = color_palette[i],\n            border = color_palette[i])\n    \n    draw_points(c(par_values_double_logistic[i, 2], par_values_double_logistic[i, 4]), \n                rep(maxdaily_precipitation * 0.9, 2),\n                color_palette[i], pch = 19)\n    \n    abline(v = par_values_double_logistic[i, 2], col = color_palette[i], lty = 2)\n    abline(v = par_values_double_logistic[i, 4], col = color_palette[i], lty = 2)\n  }\n\n  # X-axis title\n  par(mar = c(0, 0, 0, 0))\n  create_plot(c(0, 1), c(0, 1), ann = FALSE, bty = 'n', xaxt = 'n', yaxt = 'n')\n  add_text(0.5, 0.4, \"day of year\", font = 4, cex = graphic_scale * (0.7 + font_rescale))\n\n  # Infographic bits\n  draw_infographic &lt;- function(label) {\n    create_plot(c(0, 1), c(0, 1), ann = FALSE, bty = 'n', xaxt = 'n', yaxt = 'n')\n    polygon(x = arrow_pos_x[1] + (arrow_pos_x[2] - arrow_pos_x[1]) * arrow_points_x,\n            y = arrow_points_y,\n            col = rgb(0,0,0, alpha = 0.3),\n            border = NA)\n    add_text(text_pos[1], text_pos[2], \n             label, font = 4, cex = graphic_scale * (0.65 + font_rescale), adj = c(1, 0.5))\n  }\n\n  arrow_points_x &lt;- c(1/3, 2/3, 2/3, 1, 0.5, 0, 1/3, 1/3)\n  arrow_points_y &lt;- c(1, 1, 0.5, 0.5, 0, 0.5, 0.5, 1)\n  arrow_pos_x &lt;- c(0.9, 1)\n  text_pos &lt;- c(0.88, 0.4)\n\n  par(mar = c(0, 0, 0, 0))\n\n  infographic_labels &lt;- c(\n    \"gen_annual_double_logistic_curve(plateau_value, inflection1,\\nrate1, inflection2, rate2)\",\n    \"discretise_curve(curve, n_samples, max_sample_size)\\nrescale_curve(curve)\",\n    \"get_increments_from_cumulative_curve(curve) x annual_sum\"\n  )\n\n  lapply(infographic_labels, draw_infographic)\n\n  # Legend\n  par(mar = c(0, 0, 0, 0))\n  create_plot(c(0, 1), c(0, nrow(par_values_double_logistic) + 1), \n              ann = FALSE, bty = 'n', xaxt = 'n', yaxt = 'n')\n\n  y_pos &lt;- c(0.5, seq(0.1, -0.3, length.out = 3))\n  x_pos &lt;- 0.55\n  jump &lt;- 1\n\n  for (i in 1:nrow(par_values_double_logistic)) {\n    legend(x = 0, \n           y = (y_pos[1] + jump * i), \n           legend = substitute(\n             paste(\"plateau_value = \", plateau_value, \", \",\n                   \"inflection1 = \", inflection1, \", \"), \n             list(plateau_value = par_values_double_logistic[i, 1], \n                  inflection1 = par_values_double_logistic[i, 2])), \n           col = color_palette[i],\n           lwd = graphic_scale * 6, cex = graphic_scale * (0.5 + font_rescale),\n           title = NULL, \n           bty = \"n\")\n    add_text(x_pos, \n             (y_pos[2] + jump * i),\n             substitute(\n               paste(\"rate1 = \", rate1, \", \",\n                     \"inflection2 = \", inflection2, \", \",\n                     \"rate2 = \", rate2, \",\"), \n               list(rate1 = par_values_double_logistic[i, 3],\n                    inflection2 = par_values_double_logistic[i, 4],\n                    rate2 = par_values_double_logistic[i, 5])),\n             cex = graphic_scale * (0.5 + font_rescale))\n    add_text(x_pos, \n             (y_pos[3] + jump * i),\n             substitute(\n               paste(\"n_samples = \", n_samples, \", \",\n                     \"max_sample_size = \", max_sample_size), \n               list(n_samples = par_values_discretisation[i, 1],\n                    max_sample_size = par_values_discretisation[i, 2])),\n             cex = graphic_scale * (0.5 + font_rescale))\n    add_text(x_pos, \n             (y_pos[4] + jump * i),\n             substitute(\n               paste(\"annual_sum = \", annual_sum), \n               list(annual_sum = annual_sum_values[i])),\n             cex = graphic_scale * (0.5 + font_rescale))\n  }\n}\n\n# Main execution\nplot_name &lt;- file.path(output_dir, paste0(\"Fig5-annualDoubleLogisticCurve.\", plot_file_format))\n\nif (plot_file_format == \"png\") {\n  graphic_scale &lt;- 2\n  font_rescale &lt;- axis_text_rescale &lt;-  0\n  png(plot_name, width = graphic_scale * 1000, height = graphic_scale * 1000)\n} else if (plot_file_format == \"eps\") {\n  graphic_scale &lt;- 1.2\n  font_rescale &lt;- 0.1\n  axis_text_rescale &lt;- 0.1\n  extrafont::loadfonts(device = \"postscript\")\n  grDevices::cairo_ps(filename = plot_name, pointsize = 12,\n                      width = graphic_scale * 10, height = graphic_scale * 10,\n                      onefile = FALSE, family = \"sans\")\n}\nplot_annual_double_logistic(par_values_double_logistic, par_values_discretisation, annual_sum_values)\ndev.off()\n\nsvg \n  2 \n\n\n\nknitr::include_graphics(plot_name)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Demonstration of parameter variation: precipitation</span>"
    ]
  },
  {
    "objectID": "walkthrough-attempts.html",
    "href": "walkthrough-attempts.html",
    "title": "6  Calibration walk through",
    "section": "",
    "text": "6.1 Parameter estimation using optim()\nSet up six variations of parameter settings of the annual double logistic curve (i.e. plateau_value, inflection1, rate1, inflection2, rate2), the discretisation producing the annual cumulative precipitation curve (i.e. n_samples, max_sample_size) and annualPrecipitation, assuming length of year of 365 days. Random generator seed used in discretisation is fixed:\n# Fixed random seed for reproducibility\nSEED &lt;- 0\n\n# Simulation parameters\nYEAR_LENGTH &lt;- 365\n\n# Double logistic function parameters\nparams_values_double_logistic &lt;- matrix(\n  c(0.01, 125, 0.3,  245, 0.22,\n    0.15,  63, 0.55, 195, 0.6,\n    0.5,   64, 0.05, 261, 0.12,\n    0.45, 215, 0.01, 276, 0.39,\n    0.6,   20, 0.38, 254, 0.04,\n    0.85,  97, 0.24, 219, 0.17),\n  nrow = 6,\n  byrow = TRUE,\n  dimnames = list(NULL, c(\"plateau_value\", \"inflection1\", \"rate1\", \"inflection2\", \"rate2\"))\n)\n\n# Discretisation parameters\nparams_values_discretisation &lt;- matrix(\n  c(152, 22,\n    220, 10,\n    240,  6,\n    168, 13,\n    191,  9,\n    205, 17),\n  nrow = 6,\n  byrow = TRUE,\n  dimnames = list(NULL, c(\"n_samples\", \"max_sample_size\"))\n)\n\n# Annual sum values\nannual_sum_values &lt;- c(410, 1050, 636, 320, 1280, 745)\nPredefine the range of values explored for each parameter:\nparams_range_lower &lt;- c(0, 1, 0.01, 1, 0.01, 1, 3)\nparams_range_upper &lt;- c(1, 365, 0.9, 365, 0.9, 365, 30)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Calibration walk through</span>"
    ]
  },
  {
    "objectID": "walkthrough-attempts.html#parameter-estimation-using-optim",
    "href": "walkthrough-attempts.html#parameter-estimation-using-optim",
    "title": "6  Calibration walk through",
    "section": "",
    "text": "6.1.1 Calibrating gen_annual_double_logistic_curve() (deterministic function)\nSelect the first set of parameter values from the params_values_double_logistic dataset and generate the corresponding curve with the gen_annual_double_logistic_curve() function. These points will represent the original state of the model that we aim to reverse engineer from the outcome curve. Plot it.\n\noriginal_params &lt;- params_values_double_logistic[1, 1:5]\n\ncurve &lt;- gen_annual_double_logistic_curve(\n    plateau_value = original_params[1], \n    inflection1 = original_params[2], \n    rate1 = original_params[3], \n    inflection2 = original_params[4],\n    rate2 = original_params[5],\n    year_length = YEAR_LENGTH)\n\nplot(curve, cex = 2)\n\n\n\n\n\n\n\n\nDefine the initial_guess vector with your initial parameter guess values. Generate the curve using the gen_annual_double_logistic_curve() function with the initial guess. Plot it. Notice that our initial guess generates a somewhat “average” cumulative curve.\n\ninitial_guess &lt;- c(0.5, 100, 0.1, 200, 0.1)  # Initial parameter guess\n\nfirst_guess_curve &lt;- gen_annual_double_logistic_curve(\n    plateau_value = initial_guess[1], \n    inflection1 = initial_guess[2], \n    rate1 = initial_guess[3], \n    inflection2 = initial_guess[4],\n    rate2 = initial_guess[5],\n    year_length = YEAR_LENGTH)\n\nplot(first_guess_curve, cex = 2)\n\n\n\n\n\n\n\n\nDefine the eval_objective_func() function that calculates the sum of squared differences between the observed data and the predicted values, generated by the gen_annual_double_logistic_curve() function with a given parameter setting. Then, use the optim() function to estimate the best parameter values by minimizing the objective function.\nNOTE: optim() using method “L-BFGS-B”, see ?optim or:\n&gt; Byrd, R. H., Lu, P., Nocedal, J. and Zhu, C. (1995). A limited memory algorithm for bound constrained optimization. SIAM Journal on Scientific Computing, 16, 1190–1208. doi:10.1137/0916069.\n\nobserved_data &lt;- curve\n\n# Objective function to minimize (difference between observed and predicted values or \"residual\")\neval_objective_func &lt;- function(params) {\n  predicted_data &lt;- gen_annual_double_logistic_curve(params[1], params[2], params[3], params[4], params[5], YEAR_LENGTH)\n  sum((observed_data - predicted_data)^2)\n}\n\n# Use the least squares method to estimate the parameter values\nfit &lt;- optim(initial_guess, eval_objective_func,\n             method = \"L-BFGS-B\", \n             lower = params_range_lower[1:5], \n             upper = params_range_upper[1:5])\n\nbest_estimation_curve &lt;- gen_annual_double_logistic_curve(fit$par[1], fit$par[2], fit$par[3], fit$par[4], fit$par[5], YEAR_LENGTH)\n\nPlot the original curve (curve) and overlay it with the curve generated using the best estimated parameter values (best_estimation_curve). The best estimated curve is shown in red.\n\nplot(curve, cex = 2)\nlines(best_estimation_curve, col = 'red', lwd = 3)\n\n\n\n\n\n\n\n\n\nprint_parameter_comparison_table(original_params, fit, params_range_upper[1:5], params_range_lower[1:5])\n\n\n\n\n\n\noriginal\nestimated\ndelta\nrange\ndelta (%)\n\n\n\n\nplateau_value\n0.01\n0.0090998\n0.000900\n1.00\n0.0900\n\n\ninflection1\n125.00\n113.7955514\n11.204449\n364.00\n3.0781\n\n\nrate1\n0.30\n0.8999843\n0.599984\n0.89\n67.4140\n\n\ninflection2\n245.00\n244.9879056\n0.012094\n364.00\n0.0033\n\n\nrate2\n0.22\n0.2195381\n0.000462\n0.89\n0.0519\n\n\n\n\n\n\n\n\nWe can see that reverse engineering the parameter values of the double logistic curve is relatively straightforward. This specific curve offers a clear hint that rate1 and rate2 (i.e. the maximum growth rates of each logistic component) are harder to estimate when plateau_value is extreme .\n\n\n6.1.2 Adding discretise_curve() (stochastic function)\nHowever, precipitation in the Weather model presents an additional challenge: the continuous cumulative curve is broken down into “steps” through discretise_curve(), which introduces stochasticity. We will also add rescale_curve() to the end of the process, in order to approach the curve that would be created by generate_annual_precipitation().\nLet us extend the workflow used above with gen_annual_double_logistic_curve() to also cover the two additional parameters of discretise_curve() (for now, fix seed = 0):\n\noriginal_params &lt;- c(params_values_double_logistic[1, 1:5], params_values_discretisation[1, 1:2])\n\ncurve &lt;- gen_cum_precipitation_of_year(\n  plateau_value = original_params[1], \n  inflection1 = original_params[2], \n  rate1 = original_params[3], \n  inflection2 = original_params[4],\n  rate2 = original_params[5],\n  year_length = YEAR_LENGTH,\n  n_samples = original_params[6],\n  max_sample_size = original_params[7],\n  seed = SEED)\n\nplot(curve, type = 'l', lwd = 3)\n\n\n\n\n\n\n\n\n\ninitial_guess &lt;- c(0.5, 100, 0.1, 200, 0.1, 180, 15)  # Initial parameter guess\n\nfirst_guess_curve &lt;- gen_cum_precipitation_of_year(\n    plateau_value = initial_guess[1], \n    inflection1 = initial_guess[2], \n    rate1 = initial_guess[3], \n    inflection2 = initial_guess[4],\n    rate2 = initial_guess[5],\n    year_length = YEAR_LENGTH,\n    n_samples = initial_guess[6],\n    max_sample_size = initial_guess[7],\n    seed = SEED)\n\nplot(first_guess_curve, type = 'l', lwd = 3)\n\n\n\n\n\n\n\n\n\nobserved_data &lt;- curve\n\n# Objective function to minimize (difference between observed and predicted values)\neval_objective_func &lt;- function(params) {\n  predicted_data &lt;- gen_cum_precipitation_of_year(\n    plateau_value = params[1], \n    inflection1 = params[2], rate1 = params[3], \n    inflection2 = params[4], rate2 = params[5], \n    year_length = YEAR_LENGTH,\n    n_samples = params[6], \n    max_sample_size = params[7], \n    seed = SEED\n    )\n\n  sum((observed_data - predicted_data)^2)\n}\n\n# Use the least squares method to estimate the parameter values\n\nfit &lt;- optim(initial_guess, eval_objective_func,\n             method = \"L-BFGS-B\", \n             lower = params_range_lower, \n             upper = params_range_upper)\n\nbest_estimation_curve &lt;- gen_cum_precipitation_of_year(\n  plateau_value = fit$par[1], \n  inflection1 = fit$par[2], rate1 = fit$par[3], \n  inflection2 = fit$par[4], rate2 = fit$par[5], \n  year_length = YEAR_LENGTH,\n  n_samples = fit$par[6], \n  max_sample_size = fit$par[7], \n  seed = SEED\n  )\n\n\nplot(curve, type = 'l', lwd = 3)\nlines(best_estimation_curve, col = 'red', lwd = 3)\n\n\n\n\n\n\n\n\n\nprint_parameter_comparison_table(original_params, fit, params_range_upper, params_range_lower)\n\n\n\n\n\n\noriginal\nestimated\ndelta\nrange\ndelta (%)\n\n\n\n\nplateau_value\n0.01\n0.0126065\n0.002606\n1.00\n0.2606\n\n\ninflection1\n125.00\n100.2542491\n24.745751\n364.00\n6.7983\n\n\nrate1\n0.30\n0.9000000\n0.600000\n0.89\n67.4157\n\n\ninflection2\n245.00\n250.3699407\n5.369941\n364.00\n1.4753\n\n\nrate2\n0.22\n0.9000000\n0.680000\n0.89\n76.4045\n\n\nn_samples\n152.00\n143.9652346\n8.034765\n364.00\n2.2074\n\n\nmax_sample_size\n22.00\n30.0000000\n8.000000\n27.00\n29.6296\n\n\n\n\n\n\n\n\nClose, but a much worse fit than obtained with gen_annual_double_logistic_curve() only. We should take this performance in consideration going forward.\n\n\n6.1.3 Calibrating multiple example curves to determine hyperparameters\nLet us now apply the same workflow for estimating the hyperparameters able to generate an approximation of a sequence of year daily series.\nFirst, generate the original dataset based on the different configurations present in params_values_double_logistic and params_values_discretisation:\n\ncurves &lt;- list()\noriginal_params_list &lt;- list()\n\nfor (i in 1:nrow(params_values_double_logistic))\n{\n  original_params &lt;- c(params_values_double_logistic[i, 1:5], params_values_discretisation[i, 1:2])\n\n  curve &lt;- gen_cum_precipitation_of_year(\n    plateau_value = original_params[1], \n    inflection1 = original_params[2], \n    rate1 = original_params[3], \n    inflection2 = original_params[4],\n    rate2 = original_params[5],\n    year_length = YEAR_LENGTH,\n    n_samples = original_params[6],\n    max_sample_size = original_params[7],\n    seed = SEED\n    )\n\n  curves[[i]] &lt;- curve\n  original_params_list[[i]] &lt;- original_params\n}\n\nplot(curves[[1]], type = 'l', col = 1, lwd = 3, ylab = 'curve')\nfor (i in 2:length(curves))\n{\n  lines(curves[[i]], col = i,  lwd = 3)\n}\n\n\n\n\n\n\n\n\nApply optim, reusing initial_guess and eval_objective_func, to each curve and generate a sequence of best estimation curves:\n\nbest_estimation_curves &lt;- list()\nbest_estimation_fits &lt;- list()\n\nfor (i in 1:nrow(params_values_double_logistic))\n{\n  observed_data &lt;- curves[[i]]\n  \n  # Use the least squares method to estimate the parameter values\n  \n  fit &lt;- optim(initial_guess, eval_objective_func,\n               method = \"L-BFGS-B\", \n               lower = params_range_lower, \n               upper = params_range_upper)\n  \n  best_estimation_curve &lt;- gen_cum_precipitation_of_year(\n    plateau_value = fit$par[1], \n    inflection1 = fit$par[2], rate1 = fit$par[3], \n    inflection2 = fit$par[4], rate2 = fit$par[5], \n    year_length = YEAR_LENGTH,\n    n_samples = fit$par[6], \n    max_sample_size = fit$par[7], \n    seed = SEED)\n  \n  best_estimation_curves[[i]] &lt;- best_estimation_curve\n  best_estimation_fits[[i]] &lt;- fit\n}\n\nPlot original and estimated curves:\n\nlayout(matrix(1:6, nrow = 3, ncol = 2, byrow = TRUE))\npar(mar = c(0.1, 0.1, 0.1, 0.1))\nfor (i in 1:length(curves)) {\n  plot(curves[[i]], type = 'l', col = i, lwd = 3, xaxt = 'n', yaxt = 'n')\n  lines(best_estimation_curves[[i]], col = i,  lty = 2)\n}\n\n\n\n\n\n\n\n\nVisualise the aggregate estimation quality:\n\n# Helper functions\ncalculate_mean_sd &lt;- function(list_of_vectors) {\n  if (length(list_of_vectors) == 0) return(list(mean = numeric(0), sd = numeric(0)))\n  \n  values_matrix &lt;- do.call(rbind, list_of_vectors)\n  \n  list(\n    mean = colMeans(values_matrix),\n    sd = apply(values_matrix, 2, sd)\n  )\n}\n\nget_list_params_from_fit &lt;- function(list_of_fit_objects) {\n  lapply(list_of_fit_objects, `[[`, \"par\")\n}\n\n# Main functions\n\ncreate_parameter_comparison_summary &lt;- function(original_params_list, fits, params_range_upper, params_range_lower) {\n  original_summary &lt;- calculate_mean_sd(original_params_list)\n  estimated_summary &lt;- calculate_mean_sd(get_list_params_from_fit(fits))\n\n  data.frame(\n    original_mean = round(original_summary$mean, digits = 4),\n    original_sd = round(original_summary$sd, digits = 4),\n    estimated_mean = round(estimated_summary$mean, digits = 4),\n    estimated_sd = round(estimated_summary$sd, digits = 4),\n    delta_mean = round(abs(original_summary$mean - estimated_summary$mean), digits = 6),\n    delta_sd = round(abs(original_summary$sd - estimated_summary$sd), digits = 6),\n    #range = params_range_upper - params_range_lower,\n    delta_mean_percent = round(\n      100 * abs(original_summary$mean - estimated_summary$mean) / (params_range_upper - params_range_lower), \n      digits = 4\n    ),\n    delta_mean_percent = round(\n      100 * abs(original_summary$sd - estimated_summary$sd) / (params_range_upper - params_range_lower), \n      digits = 4\n    )\n  )\n}\n\nprint_parameter_comparison_summary_table &lt;- function(parameter_comparison_summary) {\n  \n  knitr::kable(parameter_comparison_summary,\n             format = \"html\",\n             col.names = c(\n               \"original (mean)\", \"original (sd)\", \n               \"estimated (mean)\", \"estimated (sd)\",\n               \"delta (mean)\", \"delta (sd)\",\n               \"delta (mean%)\", \"delta (sd%)\"),\n             align = c(\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\"))\n}\n\n# Execution\n\nparameter_comparison_summary &lt;- create_parameter_comparison_summary(original_params_list, best_estimation_fits, params_range_upper, params_range_lower)\n\nprint_parameter_comparison_summary_table(parameter_comparison_summary)\n\n\n\n\n\n\noriginal (mean)\noriginal (sd)\nestimated (mean)\nestimated (sd)\ndelta (mean)\ndelta (sd)\ndelta (mean%)\ndelta (sd%)\n\n\n\n\nplateau_value\n0.4267\n0.3051\n0.5238\n0.4174\n0.097147\n0.112358\n9.7147\n11.2358\n\n\ninflection1\n97.3333\n67.6481\n64.9747\n49.8331\n32.358633\n17.815035\n8.8897\n4.8942\n\n\nrate1\n0.2550\n0.2034\n0.4256\n0.4247\n0.170560\n0.221209\n19.1640\n24.8549\n\n\ninflection2\n241.6667\n29.6895\n256.9584\n60.9816\n15.291717\n31.292059\n4.2010\n8.5967\n\n\nrate2\n0.2567\n0.2050\n0.4631\n0.4623\n0.206456\n0.257308\n23.1973\n28.9110\n\n\nn_samples\n196.0000\n32.6741\n159.1494\n24.7352\n36.850629\n7.938989\n10.1238\n2.1810\n\n\nmax_sample_size\n12.8333\n5.8452\n21.6078\n10.1365\n8.774432\n4.291308\n32.4979\n15.8937\n\n\n\n\n\n\n\n\nAlthough the original example curves are quite different from each other, let us assume that they correspond to cumulative precipitation of six years at a single location. This will allow us to test the optim calibration workflow on our ultimate target, the precipitation hyperparameters of the Weather model.\nInitialise the weather model setting the precipitation hyperparameters as the mean and standard deviation of the best estimation parameter values in parameter_comparison_summary:\n\nweather_model &lt;- initialise_weather_model(\n    seed = 0,\n    precip_plateau_value_mean = parameter_comparison_summary[\"plateau_value\", \"estimated_mean\"],\n    precip_plateau_value_sd = parameter_comparison_summary[\"plateau_value\", \"estimated_sd\"],\n    precip_inflection1_mean = parameter_comparison_summary[\"inflection1\", \"estimated_mean\"],\n    precip_inflection1_sd = parameter_comparison_summary[\"inflection1\", \"estimated_sd\"],\n    precip_rate1_mean = parameter_comparison_summary[\"rate1\", \"estimated_mean\"],\n    precip_rate1_sd = parameter_comparison_summary[\"rate1\", \"estimated_sd\"],\n    precip_inflection2_mean = parameter_comparison_summary[\"inflection2\", \"estimated_mean\"],\n    precip_inflection2_sd = parameter_comparison_summary[\"inflection2\", \"estimated_sd\"],\n    precip_rate2_mean = parameter_comparison_summary[\"rate2\", \"estimated_mean\"],\n    precip_rate2_sd = parameter_comparison_summary[\"rate2\", \"estimated_sd\"],\n    precip_n_samples_mean = parameter_comparison_summary[\"n_samples\", \"estimated_mean\"],\n    precip_n_samples_sd = parameter_comparison_summary[\"n_samples\", \"estimated_sd\"],\n    precip_max_sample_size_mean = parameter_comparison_summary[\"max_sample_size\", \"estimated_mean\"],\n    precip_max_sample_size_sd = parameter_comparison_summary[\"max_sample_size\", \"estimated_sd\"]\n  )\n\nRun the model to generate a number of cumulative curves:\n\nweather_model &lt;- run_weather_model(weather_model, num_years = 30, show_warnings = FALSE)\n\nPlot original and generated curves:\n\nplot(c(1, weather_model$PARAMS$year_length), c(0, 1), ann = F, bty = 'n', type = 'n', ylab = 'curve')\n# original curves\nfor (i in 1:length(curves))\n{\n  lines(curves[[i]], col = i,  lwd = 3)\n}\n# generated curves\nfor (year in unique(weather_model$daily$current_year))\n{\n  lines(1:weather_model$PARAMS$year_length, \n        get_cumulative_precipitation_of_year(\n          weather_model$daily$precipitation[\n            weather_model$daily$current_year == year\n          ]), \n        col = \"grey\", \n        lty = 2)\n}",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Calibration walk through</span>"
    ]
  },
  {
    "objectID": "best-shot.html",
    "href": "best-shot.html",
    "title": "7  Calibration targeting weather examples",
    "section": "",
    "text": "7.1 Preparation\nChoose file format for generated figures:\noutput_dir &lt;- \"output\"\nplot_file_format &lt;- c(\"png\", \"eps\")[1] # modify index number to change format\nLoad source file containing the R implementation of the Weather model:\nsource(\"source/weatherModel.R\")\nsource(\"source/estimate_hyperparameters_optim.R\")\nSet simulation constants:\nSEED &lt;- 0\nYEAR_LENGTH &lt;- 365 # ignoring leap year adjustment\nSOLSTICE_SUMMER &lt;- 172  # June 21st (approx.)\nSOLSTICE_WINTER &lt;- 355  # December 21st (approx.)\nAs a final part in this demonstration, we will extend the above process to deal with multiple instances of curves and parameter sets, generated by the same configuration of hyperparameters. We will then want to estimate those original hyperparameter values.\nWe use the data downloaded at NASA´s POWER access viewer (power.larc.nasa.gov/data-access-viewer/) selecting the user community ‘Agroclimatology’ and pin pointing the different locations between 01/01/1984 and 31/12/2007. The exact locations are:\nWe selected the ICASA Format’s parameters:\nand from Solar Related Parameters:\n# Function to read and filter weather data\nread_weather_data &lt;- function(file_path) {\n  data &lt;- read.csv(file_path, skip = 18)\n  data[data$YEAR %in% 1984:2007, ]\n}\n\n# Get input file paths\ninput_files &lt;- list.files(path = \"input\", full.names = TRUE)\n\n# Read and combine all weather data\nweather &lt;- do.call(rbind, lapply(input_files, read_weather_data))\n\n# Define site mapping\nsite_mapping &lt;- list(\n  list(condition = function(x) floor(x$LAT) == 29, site = \"Rakhigarhi\"),\n  list(condition = function(x) floor(x$LON) == 104, site = \"Irkutsk\"),\n  list(condition = function(x) floor(x$LAT) == -43, site = \"Hobart\"),\n  list(condition = function(x) floor(x$LAT) == 21, site = \"Pearl Harbor\"),\n  list(condition = function(x) floor(x$LAT) == -24, site = \"Sao Paulo\"),\n  list(condition = function(x) floor(x$LON) == 0, site = \"Cambridge\"),\n  list(condition = function(x) floor(x$LAT) == -23, site = \"Windhoek\")\n)\n\n# Assign sites based on latitude and longitude\nweather$Site &lt;- NA\nfor (mapping in site_mapping) {\n  weather$Site[mapping$condition(weather)] &lt;- mapping$site\n}\n\n# Calculate summary statistics\nyears &lt;- unique(weather$YEAR)\nnumber_of_years &lt;- length(years)\n\n# Calculate the yearly length in days\nyear_length_in_days &lt;- as.integer(table(weather$YEAR) / nlevels(factor(weather$Site)))\n\nyear_length_max &lt;- max(year_length_in_days)\nPrepare display order according to latitude:\n# Create a function to format latitude\nformat_latitude &lt;- function(lat) {\n  paste(abs(round(lat, 2)), ifelse(lat &lt; 0, \"S\", \"N\"))\n}\n\n# Create and process sites_latitude data frame\nsites_latitude &lt;- data.frame(\n  Site = unique(weather$Site),\n  Latitude = as.numeric(unique(weather$LAT))\n)\n\n# Sort sites_latitude by descending latitude\nsites_latitude &lt;- sites_latitude[order(-sites_latitude$Latitude), ]\n\n# Format latitude values\nsites_latitude$Latitude &lt;- sapply(sites_latitude$Latitude, format_latitude)\n\n# calculate easy references to sites\nsites &lt;- sites_latitude$Site\nnumber_of_sites &lt;- length(sites)\nCompute statistics for each site and day of year:\n# Define summary statistics function\ncalculate_summary &lt;- function(data, column) {\n  c(mean = mean(data[[column]], na.rm = TRUE),\n    sd = sd(data[[column]], na.rm = TRUE),\n    max = max(data[[column]], na.rm = TRUE),\n    min = min(data[[column]], na.rm = TRUE),\n    error = qt(0.975, length(data[[column]]) - 1) * \n      sd(data[[column]], na.rm = TRUE) / \n      sqrt(length(data[[column]])))\n}\n\n# Initialize weather_summary as a data frame\nweather_summary &lt;- data.frame(\n  Site = character(),\n  dayOfYear = integer(),\n  solarRadiation.mean = numeric(),\n  solarRadiation.sd = numeric(),\n  solarRadiation.max = numeric(),\n  solarRadiation.min = numeric(),\n  solarRadiation.error = numeric(),\n  solarRadiationTop.mean = numeric(),\n  temperature.mean = numeric(),\n  temperature.sd = numeric(),\n  temperature.max = numeric(),\n  temperature.min = numeric(),\n  temperature.error = numeric(),\n  maxTemperature.mean = numeric(),\n  maxTemperature.max = numeric(),\n  maxTemperature.min = numeric(),\n  maxTemperature.error = numeric(),\n  minTemperature.mean = numeric(),\n  minTemperature.max = numeric(),\n  minTemperature.min = numeric(),\n  minTemperature.error = numeric(),\n  temperature.lowerDeviation = numeric(),\n  temperature.lowerDeviation.error = numeric(),\n  temperature.upperDeviation = numeric(),\n  temperature.upperDeviation.error = numeric(),\n  precipitation.mean = numeric(),\n  precipitation.max = numeric(),\n  precipitation.min = numeric(),\n  precipitation.error = numeric()\n)\n\n# Pre-allocate the weather_summary data frame\ntotal_rows &lt;- length(sites) * 366\nweather_summary &lt;- weather_summary[rep(1, total_rows), ]\n\n# Main loop\nrow_index &lt;- 1\nfor (site in sites) {\n  for (day in 1:366) {\n    weather_site_day &lt;- weather[weather$Site == site & weather$DOY == day, ]\n    \n    if (nrow(weather_site_day) == 0) next\n    \n    weather_summary[row_index, \"Site\"] &lt;- site\n    weather_summary[row_index, \"dayOfYear\"] &lt;- day\n    \n    # Solar radiation\n    solar_summary &lt;- calculate_summary(weather_site_day, \"ALLSKY_SFC_SW_DWN\")\n    weather_summary[row_index, c(\"solarRadiation.mean\", \"solarRadiation.sd\", \n                                \"solarRadiation.max\", \"solarRadiation.min\", \n                                \"solarRadiation.error\")] &lt;- solar_summary\n    \n    weather_summary[row_index, \"solarRadiationTop.mean\"] &lt;- mean(weather_site_day$ALLSKY_TOA_SW_DWN, na.rm = TRUE)\n    \n    # Temperature\n    temp_summary &lt;- calculate_summary(weather_site_day, \"T2M\")\n    weather_summary[row_index, c(\"temperature.mean\", \"temperature.sd\", \n                                \"temperature.max\", \"temperature.min\", \n                                \"temperature.error\")] &lt;- temp_summary\n    \n    # Max temperature\n    max_temp_summary &lt;- calculate_summary(weather_site_day, \"T2M_MAX\")\n    weather_summary[row_index, c(\"maxTemperature.mean\", \"maxTemperature.max\", \n                                \"maxTemperature.min\", \"maxTemperature.error\")] &lt;- max_temp_summary[c(\"mean\", \"max\", \"min\", \"error\")]\n    \n    # Min temperature\n    min_temp_summary &lt;- calculate_summary(weather_site_day, \"T2M_MIN\")\n    weather_summary[row_index, c(\"minTemperature.mean\", \"minTemperature.max\", \n                                \"minTemperature.min\", \"minTemperature.error\")] &lt;- min_temp_summary[c(\"mean\", \"max\", \"min\", \"error\")]\n    \n    # Temperature deviations\n    lower_dev &lt;- weather_site_day$T2M - weather_site_day$T2M_MIN\n    upper_dev &lt;- weather_site_day$T2M_MAX - weather_site_day$T2M\n    \n    weather_summary[row_index, \"temperature.lowerDeviation\"] &lt;- mean(lower_dev, na.rm = TRUE)\n    weather_summary[row_index, \"temperature.lowerDeviation.error\"] &lt;- qt(0.975, length(lower_dev) - 1) * \n      sd(lower_dev, na.rm = TRUE) / sqrt(length(lower_dev))\n    \n    weather_summary[row_index, \"temperature.upperDeviation\"] &lt;- mean(upper_dev, na.rm = TRUE)\n    weather_summary[row_index, \"temperature.upperDeviation.error\"] &lt;- qt(0.975, length(upper_dev) - 1) * \n      sd(upper_dev, na.rm = TRUE) / sqrt(length(upper_dev))\n    \n    # Precipitation\n    precip_summary &lt;- calculate_summary(weather_site_day, \"PRECTOT\")\n    weather_summary[row_index, c(\"precipitation.mean\", \"precipitation.max\", \n                                \"precipitation.min\", \"precipitation.error\")] &lt;- precip_summary[c(\"mean\", \"max\", \"min\", \"error\")]\n    \n    row_index &lt;- row_index + 1\n  }\n}\n\n# Remove any unused rows\nweather_summary &lt;- weather_summary[1:(row_index-1), ]",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Calibration targeting weather examples</span>"
    ]
  },
  {
    "objectID": "best-shot.html#preparation",
    "href": "best-shot.html#preparation",
    "title": "7  Calibration targeting weather examples",
    "section": "",
    "text": "Rakhigarhi, Haryana, India (Latitude: 29.1687, Longitude: 76.0687)\n\nIrkutsk, Irkutsk Óblast, Russia (Latitude: 52.2891, Longitude: 104.2493)\nHobart, Tasmania, Australia (Latitude: -42.8649, Longitude: 147.3441)\nPearl Harbor, Hawaii, United States of America (Latitude: 21.376, Longitude: -157.9708)\nSão Paulo, Brazil (Latitude: -23.5513, Longitude: -46.6344)\nCambridge, United Kingdom (Latitude: 52.2027, Longitude: 0.122)\nWindhoek, Namibia (Latitude: -22.5718, Longitude: 17.0953)\n\n\n\nPrecipitation (PRECTOT)\n\nWind speed at 2m (WS2M)\n\nRelative Humidity at 2m (RH2M)\n\nDew/frost point at 2m (T2MDEW)\n\nMaximum temperature at 2m (T2M_MAX)\n\nMinimum temperature at 2m (T2M_MIN)\n\nAll sky insolation incident on a horizontal surface (ALLSKY_SFC_SW_DWN)\n\nTemperature at 2m (T2M)\n\n\n\nTop-of-atmosphere Insolation (ALLSKY_TOA_SW_DWN)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Calibration targeting weather examples</span>"
    ]
  },
  {
    "objectID": "best-shot.html#estimation-of-annual-cumulative-precipitation-hyperparameters-based-on-weather-dataset",
    "href": "best-shot.html#estimation-of-annual-cumulative-precipitation-hyperparameters-based-on-weather-dataset",
    "title": "7  Calibration targeting weather examples",
    "section": "7.2 Estimation of annual cumulative precipitation hyperparameters based on weather dataset",
    "text": "7.2 Estimation of annual cumulative precipitation hyperparameters based on weather dataset\nDeclare auxiliary objects for estimating the precipitation cumulative curve with optim:\n\n# Define the objective function for optimization\nobjective_function &lt;- function(params, observed_data) {\n  predicted_data &lt;- gen_cum_precipitation_of_year(\n    plateau_value = params[1], \n    inflection1 = params[2], rate1 = params[3], \n    inflection2 = params[4], rate2 = params[5], \n    year_length = length(observed_data),\n    n_samples = params[6], \n    max_sample_size = params[7], \n    seed = SEED\n  )\n  sum((observed_data - predicted_data)^2)\n}\n\n\n7.2.1 Test an isolated version of the estimation of cumulative precipitation hyperparameters using optim\nPrepare data for Cambridge site:\n\ncambridge_data &lt;- subset(weather, Site == \"Cambridge\")\ncum_precip &lt;- get_cumulative_precipitation(\n  daily_precipitation = cambridge_data$PRECTOT, \n  years = cambridge_data$YEAR\n)\ncambridge_curves &lt;- split(cum_precip, cambridge_data$YEAR)\n\nChoose a good initial guess:\n\ncambridge_initial_guess &lt;- c(0.5, 122, 0.005, 243, 0.005, 180, 15)\n\ncambridge_initial_guess_curve &lt;- gen_cum_precipitation_of_year(\n    plateau_value = cambridge_initial_guess[1], \n    inflection1 =  cambridge_initial_guess[2], rate1 = cambridge_initial_guess[3], \n    inflection2 = cambridge_initial_guess[4], rate2 = cambridge_initial_guess[5], \n    year_length = YEAR_LENGTH,\n    n_samples = cambridge_initial_guess[6], \n    max_sample_size = cambridge_initial_guess[7], \n    seed = SEED\n    )\n\nVisually assess initial guess:\n\nplot(cambridge_curves[[1]], type = 'l', col = 1, lwd = 3, ylab = 'curve')\nfor (i in 2:length(cambridge_curves))\n{\n  lines(cambridge_curves[[i]], col = i,  lwd = 3)\n}\nlines(cambridge_initial_guess_curve, col = \"black\", lwd = 4, lty = 2)\n\n\n\n\n\n\n\n\nPerform parameter estimation with best initial guess:\n\ncambridge_estimation_result &lt;- estimate_hyperparameters_optim(\n  curves = cambridge_curves,\n  objective_function = objective_function,\n  method = \"L-BFGS-B\",\n  lower = c(0, 1, 0.01, 1, 0.01, 1, 3),\n  upper = c(1, 365, 0.9, 365, 0.9, 365, 30),\n  initial_guess = cambridge_initial_guess\n)\n\nUse parameter estimations to generate curves for each year:\n\ncambridge_best_estimation_curves &lt;- list()\n\nfor (year in years)\n{\n  fit_year &lt;- cambridge_estimation_result$curve_fits[[as.character(year)]]\n  \n  cambridge_best_estimation_curve &lt;- gen_cum_precipitation_of_year(\n    plateau_value = fit_year$par[1], \n    inflection1 =  fit_year$par[2], rate1 = fit_year$par[3], \n    inflection2 = fit_year$par[4], rate2 = fit_year$par[5], \n    year_length = YEAR_LENGTH,\n    n_samples = fit_year$par[6], \n    max_sample_size = fit_year$par[7], \n    seed = SEED\n  )\n  \n  cambridge_best_estimation_curves[[as.character(year)]] &lt;- cambridge_best_estimation_curve\n}\n\nVisualise fit for the first year:\n\nplot(cambridge_curves[[1]], type = 'l', col = \"grey\", lwd = 3, xaxt = 'n', yaxt = 'n')\nlines(cambridge_best_estimation_curves[[1]], \n      col = \"black\",\n      lty = 2)\n\n\n\n\n\n\n\n\nVisualise fit per year:\n\nlayout(matrix(1:length(cambridge_curves), nrow = 6, ncol = 4, byrow = TRUE))\npar(mar = c(0.1, 0.1, 0.1, 0.1))\nfor (year in years) {\n  plot(cambridge_curves[[as.character(year)]], type = 'l', col = as.character(year), lwd = 3, xaxt = 'n', yaxt = 'n')\n  lines(cambridge_best_estimation_curves[[as.character(year)]], \n        col = \"black\",#as.character(year), \n        lty = 2)\n  text(as.character(year), x = 20, y = 0.9)\n}\n\n\n\n\n\n\n\n\n\n\n7.2.2 Run estimation of cumulative precipitation hyperparameters for all sites\nPrepare data for all sites:\n\ncum_precip_per_site &lt;- setNames(lapply(sites, function(site){\n  site_data &lt;- subset(weather, Site == site)\n  cum_precip &lt;- get_cumulative_precipitation(\n    daily_precipitation = site_data$PRECTOT, \n    years = site_data$YEAR\n  )\n  site_curves &lt;- split(cum_precip, site_data$YEAR)\n}), sites)\n\nChoose best initial guess per site:\n\ninitial_guesses &lt;- setNames(lapply(sites, function(x) numeric(7)), sites)\n\ninitial_guesses[[\"Irkutsk\"]] &lt;- c(0.1, 60, 0.01, 200, 0.1, 180, 15)\ninitial_guesses[[\"Cambridge\"]] &lt;- c(0.5, 122, 0.005, 243, 0.005, 180, 15)\ninitial_guesses[[\"Rakhigarhi\"]] &lt;- c(0.2, 40, 0.1, 200, 0.1, 180, 15)\ninitial_guesses[[\"Pearl Harbor\"]] &lt;- c(0.8, 150, 0.005, 320, 0.1, 180, 15)\ninitial_guesses[[\"Windhoek\"]] &lt;- c(0.7, 80, 0.1, 330, 0.1, 180, 15)\ninitial_guesses[[\"Sao Paulo\"]] &lt;- c(0.6, 60, 0.1, 310, 0.1, 180, 15)\ninitial_guesses[[\"Hobart\"]] &lt;- c(0.5, 122, 0.005, 243, 0.005, 180, 15)\n\ninitial_guesses_curve &lt;- lapply(initial_guesses, function(x) {\n  gen_cum_precipitation_of_year(\n    plateau_value = x[1], \n    inflection1 =  x[2], rate1 = x[3], \n    inflection2 = x[4], rate2 = x[5], \n    year_length = YEAR_LENGTH,\n    n_samples = x[6], \n    max_sample_size = x[7], \n    seed = SEED\n  )\n})\n\nVisually assess initial guess:\n\nlayout(matrix(1:(length(sites)+1), nrow = 2, ncol = 4, byrow = TRUE))\npar(mar = c(0.1, 0.1, 0.1, 0.1))\n\nfor (site in sites) {\n  plot(cum_precip_per_site[[site]][[1]], type = 'l', col = 1, lwd = 3, xaxt = 'n', yaxt = 'n')\n  for (i in 2:length(cum_precip_per_site[[site]]))\n  {\n    lines(cum_precip_per_site[[site]][[i]], col = i,  lwd = 3)\n  }\n  lines(initial_guesses_curve[[site]], col = \"black\", lwd = 4, lty = 2)\n  text(site, x = 340, y = 0.05, adj = 1)\n}\nplot(c(0, 1), c(0, 1), ann = FALSE, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n\n\n\n\n\n\n\n\nPerform parameter estimation for each site and year with best initial guess:\n\n# Initialize an empty list to store results\nestimation_results &lt;- list()\n\n# Iterate over all sites\nfor (site in sites)\n{\n  site_data &lt;- subset(weather, Site == site)\n  \n  cum_precip &lt;- get_cumulative_precipitation(\n    daily_precipitation = site_data$PRECTOT, \n    years = site_data$YEAR\n    )\n  \n  curves &lt;- split(cum_precip, site_data$YEAR)\n  \n  estimation_results[[site]] &lt;- estimate_hyperparameters_optim(\n    curves = curves,\n    objective_function = objective_function,\n    method = \"L-BFGS-B\",\n    lower = c(0, 1, 0.01, 1, 0.01, 1, 3),\n    upper = c(1, 365, 0.9, 365, 0.9, 365, 30),\n    initial_guess = initial_guesses[[site]]\n  )\n}\n\nUse parameter estimations to generate curves for each site:\n\nbest_estimation_curves &lt;- list()\n\nfor (site in sites)\n{\n  for (year in years)\n  {\n    fit_year &lt;- estimation_results[[site]]$curve_fits[[as.character(year)]]\n    \n    best_estimation_curve &lt;- gen_cum_precipitation_of_year(\n      plateau_value = fit_year$par[1], \n      inflection1 =  fit_year$par[2], rate1 = fit_year$par[3], \n      inflection2 = fit_year$par[4], rate2 = fit_year$par[5], \n      year_length = YEAR_LENGTH,\n      n_samples = fit_year$par[6], \n      max_sample_size = fit_year$par[7], \n      seed = SEED\n    )\n    \n    best_estimation_curves[[site]][[as.character(year)]] &lt;- best_estimation_curve\n  }\n}\n\nVisually assess fit of multiple years per site:\n\nlayout(matrix(1:(length(sites)+1), nrow = 2, ncol = 4, byrow = TRUE))\npar(mar = c(0.1, 0.1, 0.1, 0.1))\n\nfor (site in sites) {\n  plot(c(0, max(year_length_in_days)), c(0, 1), ann = FALSE, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n  for (year in years)\n  {\n    lines(cum_precip_per_site[[site]][[as.character(year)]], col = year,  lwd = 3)\n    lines(best_estimation_curves[[site]][[as.character(year)]], col = year, lwd = 3, lty = 2)\n  }\n  text(site, x = 340, y = 0.05, adj = 1)\n}\nplot(c(0, 1), c(0, 1), ann = FALSE, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n\n\n\n\n\n\n\n\nEstimate a single parameter setting per site by averaging values per year:\n\nbest_estimation_fits_mean &lt;- list()\n\nfor (site in sites)\n{\n  parameters_per_year &lt;- list()\n  for (year in years)\n  {\n    parameters_per_year[[as.character(year)]] &lt;- estimation_results[[site]]$curve_fits[[as.character(year)]]$par\n  }\n  best_estimation_fits_mean[[site]]$mean &lt;- apply(data.frame(parameters_per_year), 1, mean)\n  best_estimation_fits_mean[[site]]$sd &lt;- apply(data.frame(parameters_per_year), 1, sd)\n}\n\nUse mean parameter estimations to generate curves for each site:\n\nbest_estimation_curves_mean &lt;- list()\n\nfor (site in sites)\n{\n  fit_site &lt;- best_estimation_fits_mean[[site]]$mean\n  \n  best_estimation_curve_mean &lt;- gen_cum_precipitation_of_year(\n    plateau_value = fit_site[1], \n    inflection1 =  fit_site[2], rate1 = fit_site[3], \n    inflection2 = fit_site[4], rate2 = fit_site[5], \n    year_length = YEAR_LENGTH,\n    n_samples = fit_site[6], \n    max_sample_size = fit_site[7], \n    seed = SEED\n  )\n  \n  best_estimation_curves_mean[[site]] &lt;- best_estimation_curve_mean\n}\n\nVisually assess fit of the single estimation per site:\n\nlayout(matrix(1:(length(sites)+1), nrow = 2, ncol = 4, byrow = TRUE))\npar(mar = c(0.1, 0.1, 0.1, 0.1))\n\nfor (site in sites) {\n  plot(c(0, max(year_length_in_days)), c(0, 1), ann = FALSE, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n  for (year in years)\n  {\n    lines(cum_precip_per_site[[site]][[as.character(year)]], col = year,  lwd = 3)\n  }\n  lines(best_estimation_curves_mean[[site]], col = \"black\", lwd = 4, lty = 2)\n  text(site, x = 340, y = 0.05, adj = 1)\n}\nplot(c(0, 1), c(0, 1), ann = FALSE, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n\n\n\n\n\n\n\n\n\nbest_estimation_fits_mean_table &lt;- list()\n\nfor (site in sites)\n{\n  best_estimation_fits_mean_table[[site]] &lt;- paste0(\n    round(best_estimation_fits_mean[[site]]$mean, digits = 4), \n    \" (&PlusMinus;\", round(best_estimation_fits_mean[[site]]$sd, digits = 4), \")\")\n}\nbest_estimation_fits_mean_table &lt;- as.data.frame(best_estimation_fits_mean_table, \n                  row.names = c(\"plateau value\", \"inflection1\", \"rate1\", \"inflection2\", \"rate2\", \"n_samples\", \"max_sample_size\"))\n\nknitr::kable(best_estimation_fits_mean_table)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIrkutsk\nCambridge\nRakhigarhi\nPearl.Harbor\nWindhoek\nSao.Paulo\nHobart\n\n\n\n\nplateau value\n0.0935 (±0.1015)\n0.3902 (±0.2624)\n0.2267 (±0.1762)\n0.783 (±0.19)\n0.814 (±0.1738)\n0.5705 (±0.1077)\n0.3987 (±0.281)\n\n\ninflection1\n60.909 (±4.4393)\n116.5566 (±24.6686)\n34.8833 (±11.7029)\n69.9943 (±69.6337)\n27.9262 (±26.9712)\n43.2431 (±23.0397)\n122.0008 (±0.0077)\n\n\nrate1\n0.1268 (±0.2551)\n0.0474 (±0.1816)\n0.5323 (±0.3584)\n0.1046 (±0.2554)\n0.3787 (±0.3929)\n0.3253 (±0.3593)\n0.01 (±0)\n\n\ninflection2\n204.3544 (±9.2733)\n262.4333 (±44.5082)\n210.5208 (±11.3796)\n325.012 (±12.8186)\n333.2413 (±11.3875)\n319.3132 (±14.9556)\n253.1712 (±34.4429)\n\n\nrate2\n0.0352 (±0.0279)\n0.01 (±0)\n0.3347 (±0.4006)\n0.3834 (±0.4011)\n0.4163 (±0.3817)\n0.0292 (±0.0095)\n0.0106 (±0.0012)\n\n\nn_samples\n178.7062 (±3.5977)\n181.7599 (±1.9596)\n178.646 (±10.3818)\n179.9609 (±9.3249)\n176.6509 (±19.3775)\n182.5667 (±3.5898)\n181.4085 (±4.7813)\n\n\nmax_sample_size\n15.0996 (±3.9922)\n13.0235 (±2.2968)\n17.2914 (±4.5612)\n13.2541 (±6.3016)\n17.0167 (±5.7825)\n16.5374 (±1.8574)\n13.6198 (±2.5149)\n\n\n\n\n\nThis approach seems not to work well on rate1 and rate2 standard deviations, which are estimated too high within the relative scale of a logistic rate. For example, Windhoek gets 0.3787 (±0.3929), according to which a normal probability distribution would cover most of the 0-1 range. A similar problem occurs with the Pearl Harbor’s and Windhoek’s inflection1 standard deviation.\nSince the purpose is to test the potential fit of the Weather model, not the optimisation approach, we proceed to divide by a third all instances of standard deviations.\n\nsd_adjustment &lt;- 0.3\n\nfor (site in sites)\n{\n  best_estimation_fits_mean[[site]]$sd[3] &lt;- best_estimation_fits_mean[[site]]$sd[3] * sd_adjustment\n  best_estimation_fits_mean[[site]]$sd[5] &lt;- best_estimation_fits_mean[[site]]$sd[5] * sd_adjustment\n}\nbest_estimation_fits_mean[[\"Pearl Harbor\"]]$sd[2] &lt;- best_estimation_fits_mean[[\"Pearl Harbor\"]]$sd[2] * sd_adjustment\nbest_estimation_fits_mean[[\"Windhoek\"]]$sd[2] &lt;- best_estimation_fits_mean[[\"Windhoek\"]]$sd[2] * sd_adjustment\n\n\nbest_estimation_fits_mean_table &lt;- list()\n\nfor (site in sites)\n{\n  best_estimation_fits_mean_table[[site]] &lt;- paste0(\n    round(best_estimation_fits_mean[[site]]$mean, digits = 4), \n    \" (&PlusMinus;\", round(best_estimation_fits_mean[[site]]$sd, digits = 4), \")\")\n}\nbest_estimation_fits_mean_table &lt;- as.data.frame(best_estimation_fits_mean_table, \n                  row.names = c(\"plateau value\", \"inflection1\", \"rate1\", \"inflection2\", \"rate2\", \"n_samples\", \"max_sample_size\"))\n\nknitr::kable(best_estimation_fits_mean_table)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIrkutsk\nCambridge\nRakhigarhi\nPearl.Harbor\nWindhoek\nSao.Paulo\nHobart\n\n\n\n\nplateau value\n0.0935 (±0.1015)\n0.3902 (±0.2624)\n0.2267 (±0.1762)\n0.783 (±0.19)\n0.814 (±0.1738)\n0.5705 (±0.1077)\n0.3987 (±0.281)\n\n\ninflection1\n60.909 (±4.4393)\n116.5566 (±24.6686)\n34.8833 (±11.7029)\n69.9943 (±20.8901)\n27.9262 (±8.0914)\n43.2431 (±23.0397)\n122.0008 (±0.0077)\n\n\nrate1\n0.1268 (±0.0765)\n0.0474 (±0.0545)\n0.5323 (±0.1075)\n0.1046 (±0.0766)\n0.3787 (±0.1179)\n0.3253 (±0.1078)\n0.01 (±0)\n\n\ninflection2\n204.3544 (±9.2733)\n262.4333 (±44.5082)\n210.5208 (±11.3796)\n325.012 (±12.8186)\n333.2413 (±11.3875)\n319.3132 (±14.9556)\n253.1712 (±34.4429)\n\n\nrate2\n0.0352 (±0.0084)\n0.01 (±0)\n0.3347 (±0.1202)\n0.3834 (±0.1203)\n0.4163 (±0.1145)\n0.0292 (±0.0028)\n0.0106 (±4e-04)\n\n\nn_samples\n178.7062 (±3.5977)\n181.7599 (±1.9596)\n178.646 (±10.3818)\n179.9609 (±9.3249)\n176.6509 (±19.3775)\n182.5667 (±3.5898)\n181.4085 (±4.7813)\n\n\nmax_sample_size\n15.0996 (±3.9922)\n13.0235 (±2.2968)\n17.2914 (±4.5612)\n13.2541 (±6.3016)\n17.0167 (±5.7825)\n16.5374 (±1.8574)\n13.6198 (±2.5149)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Calibration targeting weather examples</span>"
    ]
  },
  {
    "objectID": "best-shot.html#running-the-entire-weather-model-using-all-estimated-parameters",
    "href": "best-shot.html#running-the-entire-weather-model-using-all-estimated-parameters",
    "title": "7  Calibration targeting weather examples",
    "section": "7.3 Running the entire Weather model using all estimated parameters",
    "text": "7.3 Running the entire Weather model using all estimated parameters\nCalculate yearly summary statistics matching parameter inputs for each example location:\n\n# Define summary function for a single site\ncalculate_site_summary &lt;- function(site_data) {\n  # Daily aggregated statistics\n  daily_temp_mean &lt;- aggregate(site_data$T2M, by = list(site_data$DOY), FUN = mean)\n  daily_temp_sd &lt;- aggregate(site_data$T2M, by = list(site_data$DOY), FUN = sd)\n  daily_solar_mean &lt;- aggregate(site_data$ALLSKY_SFC_SW_DWN, by = list(site_data$DOY), FUN = mean)\n  daily_solar_sd &lt;- aggregate(site_data$ALLSKY_SFC_SW_DWN, by = list(site_data$DOY), FUN = sd)\n  \n  # Yearly precipitation aggregation\n  annual_sum &lt;- aggregate(site_data$PRECTOT, by = list(site_data$YEAR), FUN = sum)\n  \n  # Return computed values as a named list\n  list(\n    temp_annual_max = max(daily_temp_mean$x, na.rm = TRUE),\n    temp_annual_min = min(daily_temp_mean$x, na.rm = TRUE),\n    temp_daily_fluctuation = mean(daily_temp_sd$x, na.rm = TRUE),\n    temp_daily_lower_dev = mean(site_data$T2M - site_data$T2M_MIN, na.rm = TRUE),\n    temp_daily_upper_dev = mean(site_data$T2M_MAX - site_data$T2M, na.rm = TRUE),\n    solar_annual_max = max(daily_solar_mean$x, na.rm = TRUE),\n    solar_annual_min = min(daily_solar_mean$x, na.rm = TRUE),\n    solar_daily_fluctuation = mean(daily_solar_sd$x, na.rm = TRUE),\n    precip_annual_sum_mean = mean(annual_sum$x, na.rm = TRUE),\n    precip_annual_sum_sd = sd(annual_sum$x, na.rm = TRUE)\n  )\n}\n\n# Apply the function across sites\nannual_weather_summary &lt;- lapply(split(weather, weather$Site), calculate_site_summary)\n\n# Convert the list of summaries into a data frame\nannual_weather_summary_df &lt;- do.call(rbind, annual_weather_summary)\n#annual_weather_summary_df &lt;- cbind(Site = names(annual_weather_summary), annual_weather_summary_df)\n\n# Ensure the data frame structure is consistent\nannual_weather_summary_df &lt;- as.data.frame(annual_weather_summary_df)\n#rownames(annual_weather_summary_df) &lt;- NULL\n\nInitialise experiments per site using annual summary statistics and estimated yearly cumulative precipitation parameters of example locations as parameter inputs:\n\nweather_model_runs &lt;- list()\n\nfor (site in sites)\n{\n  estimation_optim &lt;- best_estimation_fits_mean[[site]]\n  \n  weather_model_runs[[site]] &lt;- initialise_weather_model(\n    year_length = year_length_in_days,\n    seed = SEED,\n    albedo = 0.4,\n    is_southern_hemisphere = weather[weather$Site == site,\"LAT\"][1] &lt; 0,\n    temp_annual_max = annual_weather_summary_df$temp_annual_max[[site]],\n    temp_annual_min = annual_weather_summary_df$temp_annual_min[[site]],\n    temp_daily_fluctuation = annual_weather_summary_df$temp_daily_fluctuation[[site]],\n    temp_daily_lower_dev = annual_weather_summary_df$temp_daily_lower_dev[[site]],\n    temp_daily_upper_dev = annual_weather_summary_df$temp_daily_upper_dev[[site]],\n    \n    solar_annual_max = annual_weather_summary_df$solar_annual_max[[site]],\n    solar_annual_min = annual_weather_summary_df$solar_annual_min[[site]],\n    solar_daily_fluctuation = annual_weather_summary_df$solar_daily_fluctuation[[site]],\n    \n    precip_annual_sum_mean = annual_weather_summary_df$precip_annual_sum_mean[[site]],\n    precip_annual_sum_sd = annual_weather_summary_df$precip_annual_sum_sd[[site]],\n    \n    precip_plateau_value_mean = estimation_optim$mean[1],\n    precip_plateau_value_sd = estimation_optim$sd[1],\n    precip_inflection1_mean = estimation_optim$mean[2],\n    precip_inflection1_sd = estimation_optim$sd[2],\n    precip_rate1_mean = estimation_optim$mean[3],\n    precip_rate1_sd = estimation_optim$sd[3],\n    precip_inflection2_mean = estimation_optim$mean[4],\n    precip_inflection2_sd = estimation_optim$sd[4],\n    precip_rate2_mean = estimation_optim$mean[5],\n    precip_rate2_sd = estimation_optim$sd[5],\n    precip_n_samples_mean = estimation_optim$mean[6],\n    precip_n_samples_sd = estimation_optim$sd[6],\n    precip_max_sample_size_mean = estimation_optim$mean[7],\n    precip_max_sample_size_sd = estimation_optim$sd[7]\n  )\n}\n\nRun experiments:\n\nfor (site in sites)\n{\n  weather_model_runs[[site]] &lt;-\n    run_weather_model(weather_model_runs[[site]], number_of_years)\n}\n\nCreate a data frame containing the daily summary statistics of simulations comparable to the one for the real data:\n\n# Function to calculate summary statistics for a single day's data\ncalculate_daily_summary &lt;- function(day_data) {\n  # Solar radiation\n  solar_mean &lt;- mean(day_data$solar_radiation, na.rm = TRUE)\n  solar_sd &lt;- sd(day_data$solar_radiation, na.rm = TRUE)\n  solar_max &lt;- max(day_data$solar_radiation, na.rm = TRUE)\n  solar_min &lt;- min(day_data$solar_radiation, na.rm = TRUE)\n  solar_error &lt;- qt(0.975, df = max(length(day_data$solar_radiation) - 1, 1)) * \n                 solar_sd / sqrt(length(day_data$solar_radiation))\n\n  # Temperature\n  temp_mean &lt;- mean(day_data$temperature, na.rm = TRUE)\n  temp_sd &lt;- sd(day_data$temperature, na.rm = TRUE)\n  temp_max &lt;- max(day_data$temperature, na.rm = TRUE)\n  temp_min &lt;- min(day_data$temperature, na.rm = TRUE)\n  temp_error &lt;- qt(0.975, df = max(length(day_data$temperature) - 1, 1)) * \n                temp_sd / sqrt(length(day_data$temperature))\n\n  # Max temperature\n  max_temp_mean &lt;- mean(day_data$temperature_max, na.rm = TRUE)\n  max_temp_max &lt;- max(day_data$temperature_max, na.rm = TRUE)\n  max_temp_min &lt;- min(day_data$temperature_max, na.rm = TRUE)\n  max_temp_error &lt;- qt(0.975, df = max(length(day_data$temperature_max) - 1, 1)) * \n                    sd(day_data$temperature_max, na.rm = TRUE) /\n                    sqrt(length(day_data$temperature_max))\n\n  # Min temperature\n  min_temp_mean &lt;- mean(day_data$temperature_min, na.rm = TRUE)\n  min_temp_max &lt;- max(day_data$temperature_min, na.rm = TRUE)\n  min_temp_min &lt;- min(day_data$temperature_min, na.rm = TRUE)\n  min_temp_error &lt;- qt(0.975, df = max(length(day_data$temperature_min) - 1, 1)) * \n                    sd(day_data$temperature_min, na.rm = TRUE) /\n                    sqrt(length(day_data$temperature_min))\n\n  # Deviations\n  lower_dev &lt;- mean(day_data$temperature - day_data$temperature_min, na.rm = TRUE)\n  lower_dev_error &lt;- qt(0.975, df = max(length(day_data$temperature_min) - 1, 1)) * \n                     sd(day_data$temperature - day_data$temperature_min, na.rm = TRUE) /\n                     sqrt(length(day_data$temperature_min))\n\n  upper_dev &lt;- mean(day_data$temperature_max - day_data$temperature, na.rm = TRUE)\n  upper_dev_error &lt;- qt(0.975, df = max(length(day_data$temperature_max) - 1, 1)) * \n                     sd(day_data$temperature_max - day_data$temperature, na.rm = TRUE) /\n                     sqrt(length(day_data$temperature_max))\n\n  # Precipitation\n  precip_mean &lt;- mean(day_data$precipitation, na.rm = TRUE)\n  precip_max &lt;- max(day_data$precipitation, na.rm = TRUE)\n  precip_min &lt;- min(day_data$precipitation, na.rm = TRUE)\n  precip_error &lt;- qt(0.975, df = max(length(day_data$precipitation) - 1, 1)) * \n                  sd(day_data$precipitation, na.rm = TRUE) /\n                  sqrt(length(day_data$precipitation))\n\n  # Combine results into a named list\n  list(\n    solarRadiation.mean = solar_mean,\n    solarRadiation.sd = solar_sd,\n    solarRadiation.max = solar_max,\n    solarRadiation.min = solar_min,\n    solarRadiation.error = solar_error,\n    temperature.mean = temp_mean,\n    temperature.sd = temp_sd,\n    temperature.max = temp_max,\n    temperature.min = temp_min,\n    temperature.error = temp_error,\n    maxTemperature.mean = max_temp_mean,\n    maxTemperature.max = max_temp_max,\n    maxTemperature.min = max_temp_min,\n    maxTemperature.error = max_temp_error,\n    minTemperature.mean = min_temp_mean,\n    minTemperature.max = min_temp_max,\n    minTemperature.min = min_temp_min,\n    minTemperature.error = min_temp_error,\n    temperature.lowerDeviation = lower_dev,\n    temperature.lowerDeviation.error = lower_dev_error,\n    temperature.upperDeviation = upper_dev,\n    temperature.upperDeviation.error = upper_dev_error,\n    precipitation.mean = precip_mean,\n    precipitation.max = precip_max,\n    precipitation.min = precip_min,\n    precipitation.error = precip_error\n  )\n}\n\n# Process data for all sites and days\nweather_summary_sim &lt;- do.call(rbind, lapply(sites, function(site) {\n  site_data &lt;- as.data.frame(weather_model_runs[[site]]$daily)\n  do.call(rbind, lapply(1:max(year_length_in_days), function(day) {\n    day_data &lt;- site_data[site_data$current_day_of_year == day,]\n    as.data.frame(list(\n      Site = site, \n      day_of_year = day, \n      calculate_daily_summary(day_data)\n      ))\n  }))\n}))\n\n# Convert to a data frame\nweather_summary_sim &lt;- as.data.frame(weather_summary_sim)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Calibration targeting weather examples</span>"
    ]
  },
  {
    "objectID": "best-shot.html#creating-figure",
    "href": "best-shot.html#creating-figure",
    "title": "7  Calibration targeting weather examples",
    "section": "7.4 Creating figure",
    "text": "7.4 Creating figure\nSet colours for real and simulated data:\n\nrealDataColour = hsv(200/360, 62/100, 63/100) # teal\n\nsimulatedDataColour = hsv(24/360, 79/100, 89/100) # orange\n\nCreate figure:\n\n# Helper functions\nround_to_multiple &lt;- function(x, base, round_fn = round) {\n  round_fn(x / base) * base\n}\n\ncreate_polygon &lt;- function(x, y1, y2, alpha = 0.5, col = \"black\") {\n  polygon(c(x, rev(x)), c(y1, rev(y2)), col = adjustcolor(col, alpha = alpha), border = NA)\n}\n\nplot_weather_variable &lt;- function(x, y, ylim, lwd, col = \"black\", lty = 1) {\n  plot(x, y, axes = FALSE, ylim = ylim, type = \"l\", lwd = lwd, col = col, lty = lty)\n}\n\nadd_confidence_interval &lt;- function(x, y_mean, error, col, alpha = 0.5) {\n  create_polygon(x, y_mean + error, y_mean, alpha, col)\n  create_polygon(x, y_mean - error, y_mean, alpha, col)\n}\n\nadd_min_max_interval &lt;- function(x, y_mean, y_min, y_max, col, alpha = 0.3) {\n  create_polygon(x, y_max, y_mean, alpha, col)\n  create_polygon(x, y_min, y_mean, alpha, col)\n}\n\n# Main plotting function\n\nplot_weather_summary_comparison &lt;- function(weather_summary, sites, sites_latitude, weather) {\n  # Setup plot\n  num_columns &lt;- length(sites) + 1\n  num_rows_except_bottom &lt;- 4\n  \n  layout_matrix &lt;- rbind(\n    matrix(1:(num_columns * num_rows_except_bottom), nrow = num_rows_except_bottom, ncol = num_columns, byrow = FALSE),\n    c((num_columns * num_rows_except_bottom) + 1, rep((num_columns * num_rows_except_bottom) + 2, length(sites)))\n  )\n  \n  layout(layout_matrix,\n         widths = c(3, 12, rep(10, length(sites) - 2), 14),\n         heights = c(3, 10, 10, 12, 2))\n  \n  # Y-axis labels\n  y_labs &lt;- c(expression(paste(\"solar radiation (\", MJ/m^-2, \")\")),\n             \"temperature (C)\", \"precipitation (mm)\")\n  \n  # Calculate ranges\n  range_solar &lt;- c(\n    round_to_multiple(min(\n      min(weather_summary$solarRadiation.min),\n      min(weather_summary_sim$solarRadiation.min)), \n      5, floor),\n    round_to_multiple(max(\n      max(weather_summary$solarRadiation.max),\n      40),\n      #max(weather_summary_sim$solarRadiation.max)), \n      ## an outlier in Sao Paulo brings it to c. 46 and does not show with the polygon\n      5, ceiling)\n  )\n  range_temp &lt;- c(\n    round_to_multiple(min(\n      min(weather_summary$minTemperature.min),\n      min(weather_summary_sim$minTemperature.min)), \n      5, floor),\n    round_to_multiple(max(\n      max(weather_summary$maxTemperature.max),\n      max(weather_summary_sim$maxTemperature.max)),\n      5, ceiling)\n  )\n  range_precip &lt;- c(\n    round_to_multiple(min(\n      min(weather_summary$precipitation.min),\n      min(weather_summary_sim$precipitation.min)), \n      5, floor),\n    round_to_multiple(max(\n      max(weather_summary$precipitation.max),\n      max(weather_summary_sim$precipitation.max)),\n      5, ceiling)\n  )\n  \n  # Plot settings\n  par(cex = graphic_scale, cex.axis = graphic_scale * (0.8 + axis_text_rescale))\n  \n  # First column: y axis titles\n  for (i in 1:4) {\n    par(mar = c(0, 0, 0, 0.4))\n    plot(c(0, 1), c(0, 1), ann = FALSE, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n    if (i &gt; 1) {\n      text(x = 0.5, y = 0.5, font = 4, \n           cex = graphic_scale * (0.78 + font_rescale), \n           srt = 90,\n           labels = y_labs[i-1])\n    }\n  }\n  \n  # Plot for each site\n  for (site in sites) {\n    weather_site &lt;- weather[weather$Site == site,]\n    weather_model_site &lt;- weather_model_runs[[site]]$daily\n    weather_summary_site &lt;- weather_summary[weather_summary$Site == site,]\n    weather_summary_site_sim &lt;- weather_summary_sim[weather_summary_sim$Site == site,]\n    \n    left_plot_margin &lt;- ifelse(site == sites[1], 2, 0.1)\n    right_plot_margin &lt;- ifelse(site == sites[length(sites)], 4, 0.1)\n    \n    # Site name + latitude\n    par(mar = c(0.2, left_plot_margin, 0.1, right_plot_margin))\n    plot(c(0, 1), c(0, 1), ann = FALSE, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n    text(x = 0.5, y = 0.5, font = 4, \n         cex = graphic_scale * (0.7 + font_rescale),\n         labels = paste(site, sites_latitude$Latitude[sites_latitude$Site == site], sep = \"\\n\"))\n    \n    # Solar radiation\n    \n    # original data\n    par(mar = c(0.1, left_plot_margin, 0.1, right_plot_margin))\n    plot_weather_variable(1:year_length_max, weather_summary_site$solarRadiation.mean, \n                          range_solar, graphic_scale, \n                          col = adjustcolor(realDataColour, alpha.f = 1))\n    add_confidence_interval(1:year_length_max, weather_summary_site$solarRadiation.mean, \n                            weather_summary_site$solarRadiation.error, \n                            adjustcolor(realDataColour, alpha.f = 0.75))\n    add_min_max_interval(1:year_length_max, \n                         weather_summary_site$solarRadiation.mean, \n                         weather_summary_site$solarRadiation.min, \n                         weather_summary_site$solarRadiation.max, \n                         adjustcolor(realDataColour, alpha.f = 0.5))\n    \n    # simulations\n    lines(1:year_length_max, weather_summary_site_sim$solarRadiation.mean, \n          lwd = graphic_scale, \n          col = adjustcolor(simulatedDataColour, alpha.f = 1))\n    add_confidence_interval(1:year_length_max, \n                            weather_summary_site_sim$solarRadiation.mean, \n                            weather_summary_site_sim$solarRadiation.error, \n                            adjustcolor(simulatedDataColour, alpha.f = 0.75))\n    add_min_max_interval(1:year_length_max, \n                         weather_summary_site_sim$solarRadiation.mean, \n                         weather_summary_site_sim$solarRadiation.min, \n                         weather_summary_site_sim$solarRadiation.max, \n                         adjustcolor(simulatedDataColour, alpha.f = 0.5))\n    \n    # solstices and axes\n    #lines(1:year_length_max, weather_summary_site$solarRadiationTop.mean, lty = 2, lwd = graphic_scale)\n    \n    abline(v = c(SOLSTICE_SUMMER, SOLSTICE_WINTER), lty = 3, lwd = graphic_scale)\n    \n    if (site == sites[1]) {\n      axis(2, at = seq(range_solar[1], range_solar[2], 5))\n    }\n  \n    # Temperature\n    \n    # original data\n    plot_weather_variable(1:year_length_max, weather_summary_site$temperature.mean, \n                          range_temp, graphic_scale,\n                          col = adjustcolor(realDataColour, alpha.f = 1))\n    add_confidence_interval(1:year_length_max, \n                            weather_summary_site$temperature.mean, \n                            weather_summary_site$temperature.error,\n                            adjustcolor(realDataColour, alpha.f = 0.75))\n    add_min_max_interval(1:year_length_max, \n                         weather_summary_site$temperature.mean, \n                         weather_summary_site$temperature.min, \n                         weather_summary_site$temperature.max, \n                         adjustcolor(realDataColour, alpha.f = 0.5))\n    \n    lines(1:year_length_max, weather_summary_site$maxTemperature.mean, \n          lwd = graphic_scale, \n          col = adjustcolor(realDataColour, alpha.f = 1))\n    add_confidence_interval(1:year_length_max, \n                            weather_summary_site$maxTemperature.mean, \n                            weather_summary_site$maxTemperature.error, \n                            col = adjustcolor(realDataColour, alpha.f = 0.75))\n    add_min_max_interval(1:year_length_max, \n                         weather_summary_site$maxTemperature.mean, \n                         weather_summary_site$maxTemperature.min, \n                         weather_summary_site$maxTemperature.max, \n                         adjustcolor(realDataColour, alpha.f = 0.5))\n    \n    lines(1:year_length_max, weather_summary_site$minTemperature.mean, \n          lwd = graphic_scale, \n          col = adjustcolor(realDataColour, alpha.f = 1))\n    add_confidence_interval(1:year_length_max, \n                            weather_summary_site$minTemperature.mean, \n                            weather_summary_site$minTemperature.error, \n                            adjustcolor(realDataColour, alpha.f = 0.75))\n    add_min_max_interval(1:year_length_max, \n                         weather_summary_site$minTemperature.mean, \n                         weather_summary_site$minTemperature.min, \n                         weather_summary_site$minTemperature.max, \n                         adjustcolor(realDataColour, alpha.f = 0.5))\n\n    # simulations\n    lines(1:year_length_max, weather_summary_site_sim$temperature.mean, \n          lwd = graphic_scale,\n          col = adjustcolor(simulatedDataColour, alpha.f = 1))\n    add_confidence_interval(1:year_length_max, \n                            weather_summary_site_sim$temperature.mean, \n                            weather_summary_site_sim$temperature.error,\n                            adjustcolor(simulatedDataColour, alpha.f = 0.75))\n    add_min_max_interval(1:year_length_max, \n                         weather_summary_site_sim$temperature.mean, \n                         weather_summary_site_sim$temperature.min, \n                         weather_summary_site_sim$temperature.max, \n                         adjustcolor(simulatedDataColour, alpha.f = 0.5))\n    \n    lines(1:year_length_max, weather_summary_site_sim$maxTemperature.mean, \n          lwd = graphic_scale, \n          col = adjustcolor(simulatedDataColour, alpha.f = 1))\n    add_confidence_interval(1:year_length_max, \n                            weather_summary_site_sim$maxTemperature.mean, \n                            weather_summary_site_sim$maxTemperature.error, \n                            col = adjustcolor(simulatedDataColour, alpha.f = 0.75))\n    add_min_max_interval(1:year_length_max, \n                         weather_summary_site_sim$maxTemperature.mean, \n                         weather_summary_site_sim$maxTemperature.min, \n                         weather_summary_site_sim$maxTemperature.max, \n                         adjustcolor(simulatedDataColour, alpha.f = 0.5))\n    \n    lines(1:year_length_max, weather_summary_site_sim$minTemperature.mean, \n          lwd = graphic_scale, \n          col = adjustcolor(simulatedDataColour, alpha.f = 1))\n    add_confidence_interval(1:year_length_max, \n                            weather_summary_site_sim$minTemperature.mean, \n                            weather_summary_site_sim$minTemperature.error, \n                            adjustcolor(simulatedDataColour, alpha.f = 0.75))\n    add_min_max_interval(1:year_length_max, \n                         weather_summary_site_sim$minTemperature.mean, \n                         weather_summary_site_sim$minTemperature.min, \n                         weather_summary_site_sim$minTemperature.max, \n                         adjustcolor(simulatedDataColour, alpha.f = 0.5))\n\n    # solstices and axes\n    abline(v = c(SOLSTICE_SUMMER, SOLSTICE_WINTER), lty = 3, lwd = graphic_scale)\n    \n    if (site == sites[1]) {\n      axis(2, at = seq(range_temp[1], range_temp[2], 5))\n    }\n\n    # Precipitation\n    par(mar = c(8, left_plot_margin, 0.1, right_plot_margin))\n    \n    # cumulative precipitation\n    plot(c(1, year_length_max), c(0, 1), ann = FALSE, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n    # original data\n    for (year in years) {\n      site_year_data &lt;- weather_site$PRECTOT[weather_site$YEAR == year]\n      lines(1:length(site_year_data), \n            get_cumulative_precipitation_of_year(site_year_data), \n            lwd = graphic_scale, \n            col = adjustcolor(realDataColour, alpha.f = 0.5))\n    }\n    # simulation\n    for (year in 1:number_of_years) {\n      site_year_data_sim &lt;- weather_model_site$precipitation[weather_model_site$current_year == year]\n      lines(1:length(site_year_data_sim), \n            get_cumulative_precipitation_of_year(site_year_data_sim), \n            lwd = graphic_scale, \n            col = adjustcolor(simulatedDataColour, alpha.f = 0.5))\n    }\n    \n    if (site == sites[length(sites)]) {\n      axis(4, at = seq(0, 1, 0.25))\n      mtext(\"cumulative annual sum\", 4, line = 2.5, cex = graphic_scale * (1.5 + margin_text_rescale))\n    }\n    \n    # daily precipitation\n    par(new = TRUE, mar = c(3, left_plot_margin, 0.1, right_plot_margin))\n    \n    # original data\n    plot_weather_variable(1:year_length_max, \n                          weather_summary_site$precipitation.mean, \n                          range_precip, \n                          graphic_scale, \n                          col = adjustcolor(realDataColour, alpha.f = 0.5))\n    add_confidence_interval(1:year_length_max, \n                            weather_summary_site$precipitation.mean, \n                            weather_summary_site$precipitation.error, \n                            adjustcolor(realDataColour, alpha.f = 0.5))\n    add_min_max_interval(1:year_length_max, \n                         weather_summary_site$precipitation.mean, \n                         weather_summary_site$precipitation.min, \n                         weather_summary_site$precipitation.max, \n                         adjustcolor(realDataColour, alpha.f = 0.5))\n    \n    # simulation\n    lines(1:year_length_max, \n          weather_summary_site_sim$precipitation.mean, \n          lwd = graphic_scale, \n          col = adjustcolor(simulatedDataColour, alpha.f = 0.5))\n    add_confidence_interval(1:year_length_max, \n                            weather_summary_site_sim$precipitation.mean, \n                            weather_summary_site_sim$precipitation.error, \n                            adjustcolor(simulatedDataColour, alpha.f = 0.5))\n    add_min_max_interval(1:year_length_max, \n                         weather_summary_site_sim$precipitation.mean, \n                         weather_summary_site_sim$precipitation.min, \n                         weather_summary_site_sim$precipitation.max, \n                         adjustcolor(simulatedDataColour, alpha.f = 0.5))\n    \n    # solstices and axes\n    abline(v = c(SOLSTICE_SUMMER, SOLSTICE_WINTER), lty = 3, lwd = graphic_scale)\n    \n    if (site == sites[1]) {\n      axis(2, at = seq(range_precip[1], range_precip[2], 50))\n    }\n    \n    axis(1, at = cumsum(c(31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31)), las = 2)\n  }\n  \n  # Bottom row: \"day of year\" label\n  par(mar = c(0, 0, 0, 0))\n  plot(c(0, 1), c(0, 1), ann = FALSE, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n  plot(c(0, 1), c(0, 1), ann = FALSE, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n  text(x = 0.5, y = 0.7, font = 4, \n       cex = graphic_scale * (0.8 + font_rescale),\n       labels = \"day of year\")\n}\n\n# Main execution\nplot_name &lt;- file.path(output_dir, paste0(\"Fig6-ValidationUsingExamples.\", plot_file_format))\n\nif (plot_file_format == \"png\") {\n  graphic_scale &lt;- 2\n  font_rescale &lt;- axis_text_rescale &lt;- margin_text_rescale &lt;- 0\n\n  png(plot_name, width = number_of_sites * graphic_scale * 150, height = graphic_scale * 800)\n} else if (plot_file_format == \"eps\") {\n  graphic_scale = 1.2\n  font_rescale = 0.1\n  axis_text_rescale = -0.1\n  margin_text_rescale = -0.5\n\n  extrafont::loadfonts(device = \"postscript\")\n  grDevices::cairo_ps(filename = plot_name ,\n                      pointsize = 12,\n                      width = number_of_sites * graphic_scale * 1.5,\n                      height = graphic_scale * 8,\n                      onefile = FALSE,\n                      family = \"sans\"\n                      )\n}\nplot_weather_summary_comparison(weather_summary, sites, sites_latitude, weather)\ndev.off()\n\nsvg \n  2 \n\n\n\nknitr::include_graphics(plot_name)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Calibration targeting weather examples</span>"
    ]
  }
]